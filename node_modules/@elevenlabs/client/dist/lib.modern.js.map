{"version":3,"file":"lib.modern.js","sources":["../src/BaseConversation.ts","../src/utils/BaseConnection.ts","../src/version.ts","../src/utils/events.ts","../src/utils/overrides.ts","../src/utils/WebSocketConnection.ts","../src/utils/audio.ts","../src/utils/createWorkletModuleLoader.ts","../src/utils/rawAudioProcessor.generated.ts","../src/utils/WebRTCConnection.ts","../src/utils/ConnectionFactory.ts","../src/utils/compatibility.ts","../src/utils/applyDelay.ts","../src/TextConversation.ts","../src/utils/input.ts","../src/utils/audioConcatProcessor.generated.ts","../src/utils/output.ts","../src/VoiceConversation.ts","../src/utils/postOverallFeedback.ts","../src/scribe/connection.ts","../src/utils/scribeAudioProcessor.generated.ts","../src/scribe/scribe.ts","../src/index.ts"],"sourcesContent":["import { Callbacks, Mode, Status } from \"@elevenlabs/types\";\nimport type {\n  BaseConnection,\n  DisconnectionDetails,\n  SessionConfig,\n  FormatConfig,\n} from \"./utils/BaseConnection\";\nimport type {\n  AgentAudioEvent,\n  AgentChatResponsePartEvent,\n  AgentResponseEvent,\n  ClientToolCallEvent,\n  IncomingSocketEvent,\n  InternalTentativeAgentResponseEvent,\n  InterruptionEvent,\n  UserTranscriptionEvent,\n  VadScoreEvent,\n  MCPToolCallClientEvent,\n  AgentToolResponseEvent,\n  ConversationMetadataEvent,\n  AsrInitiationMetadataEvent,\n  MCPConnectionStatusEvent,\n  ErrorMessageEvent,\n} from \"./utils/events\";\nimport type { InputConfig } from \"./utils/input\";\nimport type { OutputConfig } from \"./utils/output\";\n\nexport type { Role, Mode, Status, Callbacks } from \"@elevenlabs/types\";\n\n/** Allows self-hosting the worklets to avoid whitelisting blob: and data: in the CSP script-src  */\nexport type AudioWorkletConfig = {\n  workletPaths?: {\n    rawAudioProcessor?: string;\n    audioConcatProcessor?: string;\n  };\n  libsampleratePath?: string;\n};\n\nexport type Options = SessionConfig &\n  Callbacks &\n  ClientToolsConfig &\n  InputConfig &\n  OutputConfig &\n  AudioWorkletConfig;\n\nexport type PartialOptions = SessionConfig &\n  Partial<Callbacks> &\n  Partial<ClientToolsConfig> &\n  Partial<InputConfig> &\n  Partial<OutputConfig> &\n  Partial<FormatConfig> &\n  Partial<AudioWorkletConfig>;\n\nexport type ClientToolsConfig = {\n  clientTools: Record<\n    string,\n    (\n      parameters: any\n    ) => Promise<string | number | void> | string | number | void\n  >;\n};\n\nconst EMPTY_FREQUENCY_DATA = new Uint8Array(0);\n\nexport class BaseConversation {\n  protected lastInterruptTimestamp = 0;\n  protected mode: Mode = \"listening\";\n  protected status: Status = \"connecting\";\n  protected volume = 1;\n  protected currentEventId = 1;\n  protected lastFeedbackEventId = 0;\n  protected canSendFeedback = false;\n\n  protected static getFullOptions(partialOptions: PartialOptions): Options {\n    return {\n      clientTools: {},\n      onConnect: () => {},\n      onDebug: () => {},\n      onDisconnect: () => {},\n      onError: () => {},\n      onMessage: () => {},\n      onAudio: () => {},\n      onModeChange: () => {},\n      onStatusChange: () => {},\n      onCanSendFeedbackChange: () => {},\n      onInterruption: () => {},\n      ...partialOptions,\n    };\n  }\n\n  protected constructor(\n    protected readonly options: Options,\n    protected readonly connection: BaseConnection\n  ) {\n    if (this.options.onConnect) {\n      this.options.onConnect({ conversationId: connection.conversationId });\n    }\n    this.connection.onMessage(this.onMessage);\n    this.connection.onDisconnect(this.endSessionWithDetails);\n    this.connection.onModeChange(mode => this.updateMode(mode));\n    this.updateStatus(\"connected\");\n  }\n\n  public endSession() {\n    return this.endSessionWithDetails({ reason: \"user\" });\n  }\n\n  private endSessionWithDetails = async (details: DisconnectionDetails) => {\n    if (this.status !== \"connected\" && this.status !== \"connecting\") return;\n    this.updateStatus(\"disconnecting\");\n    await this.handleEndSession();\n    this.updateStatus(\"disconnected\");\n    if (this.options.onDisconnect) {\n      this.options.onDisconnect(details);\n    }\n  };\n\n  protected async handleEndSession() {\n    this.connection.close();\n  }\n\n  protected updateMode(mode: Mode) {\n    if (mode !== this.mode) {\n      this.mode = mode;\n      if (this.options.onModeChange) {\n        this.options.onModeChange({ mode });\n      }\n    }\n  }\n\n  protected updateStatus(status: Status) {\n    if (status !== this.status) {\n      this.status = status;\n      if (this.options.onStatusChange) {\n        this.options.onStatusChange({ status });\n      }\n    }\n  }\n\n  protected updateCanSendFeedback() {\n    const canSendFeedback = this.currentEventId !== this.lastFeedbackEventId;\n    if (this.canSendFeedback !== canSendFeedback) {\n      this.canSendFeedback = canSendFeedback;\n      if (this.options.onCanSendFeedbackChange) {\n        this.options.onCanSendFeedbackChange({ canSendFeedback });\n      }\n    }\n  }\n\n  protected handleInterruption(event: InterruptionEvent) {\n    if (event.interruption_event) {\n      this.lastInterruptTimestamp = event.interruption_event.event_id;\n\n      if (this.options.onInterruption) {\n        this.options.onInterruption({\n          event_id: event.interruption_event.event_id,\n        });\n      }\n    }\n  }\n\n  protected handleAgentResponse(event: AgentResponseEvent) {\n    if (this.options.onMessage) {\n      this.options.onMessage({\n        source: \"ai\",\n        message: event.agent_response_event.agent_response,\n      });\n    }\n  }\n\n  protected handleUserTranscript(event: UserTranscriptionEvent) {\n    if (this.options.onMessage) {\n      this.options.onMessage({\n        source: \"user\",\n        message: event.user_transcription_event.user_transcript,\n      });\n    }\n  }\n\n  protected handleTentativeAgentResponse(\n    event: InternalTentativeAgentResponseEvent\n  ) {\n    if (this.options.onDebug) {\n      this.options.onDebug({\n        type: \"tentative_agent_response\",\n        response:\n          event.tentative_agent_response_internal_event\n            .tentative_agent_response,\n      });\n    }\n  }\n\n  protected handleVadScore(event: VadScoreEvent) {\n    if (this.options.onVadScore) {\n      this.options.onVadScore({\n        vadScore: event.vad_score_event.vad_score,\n      });\n    }\n  }\n\n  protected async handleClientToolCall(event: ClientToolCallEvent) {\n    if (\n      Object.prototype.hasOwnProperty.call(\n        this.options.clientTools,\n        event.client_tool_call.tool_name\n      )\n    ) {\n      try {\n        const result =\n          (await this.options.clientTools[event.client_tool_call.tool_name](\n            event.client_tool_call.parameters\n          )) ?? \"Client tool execution successful.\"; // default client-tool call response\n\n        // The API expects result to be a string, so we need to convert it if it's not already a string\n        const formattedResult =\n          typeof result === \"object\" ? JSON.stringify(result) : String(result);\n\n        this.connection.sendMessage({\n          type: \"client_tool_result\",\n          tool_call_id: event.client_tool_call.tool_call_id,\n          result: formattedResult,\n          is_error: false,\n        });\n      } catch (e) {\n        this.onError(\n          `Client tool execution failed with following error: ${(e as Error)?.message}`,\n          {\n            clientToolName: event.client_tool_call.tool_name,\n          }\n        );\n        this.connection.sendMessage({\n          type: \"client_tool_result\",\n          tool_call_id: event.client_tool_call.tool_call_id,\n          result: `Client tool execution failed: ${(e as Error)?.message}`,\n          is_error: true,\n        });\n      }\n    } else {\n      if (this.options.onUnhandledClientToolCall) {\n        this.options.onUnhandledClientToolCall(event.client_tool_call);\n\n        return;\n      }\n\n      this.onError(\n        `Client tool with name ${event.client_tool_call.tool_name} is not defined on client`,\n        {\n          clientToolName: event.client_tool_call.tool_name,\n        }\n      );\n      this.connection.sendMessage({\n        type: \"client_tool_result\",\n        tool_call_id: event.client_tool_call.tool_call_id,\n        result: `Client tool with name ${event.client_tool_call.tool_name} is not defined on client`,\n        is_error: true,\n      });\n    }\n  }\n\n  protected handleAudio(event: AgentAudioEvent) {}\n\n  protected handleMCPToolCall(event: MCPToolCallClientEvent) {\n    if (this.options.onMCPToolCall) {\n      this.options.onMCPToolCall(event.mcp_tool_call);\n    }\n  }\n\n  protected handleMCPConnectionStatus(event: MCPConnectionStatusEvent) {\n    if (this.options.onMCPConnectionStatus) {\n      this.options.onMCPConnectionStatus(event.mcp_connection_status);\n    }\n  }\n\n  protected handleAgentToolResponse(event: AgentToolResponseEvent) {\n    if (event.agent_tool_response.tool_name === \"end_call\") {\n      this.endSessionWithDetails({\n        reason: \"agent\",\n        context: new CloseEvent(\"end_call\", { reason: \"Agent ended the call\" }),\n      });\n    }\n\n    if (this.options.onAgentToolResponse) {\n      this.options.onAgentToolResponse(event.agent_tool_response);\n    }\n  }\n\n  protected handleConversationMetadata(event: ConversationMetadataEvent) {\n    if (this.options.onConversationMetadata) {\n      this.options.onConversationMetadata(\n        event.conversation_initiation_metadata_event\n      );\n    }\n  }\n\n  protected handleAsrInitiationMetadata(event: AsrInitiationMetadataEvent) {\n    if (this.options.onAsrInitiationMetadata) {\n      this.options.onAsrInitiationMetadata(event.asr_initiation_metadata_event);\n    }\n  }\n\n  protected handleAgentChatResponsePart(event: AgentChatResponsePartEvent) {\n    if (this.options.onAgentChatResponsePart) {\n      this.options.onAgentChatResponsePart(event.text_response_part);\n    }\n  }\n\n  protected handleErrorEvent(event: ErrorMessageEvent) {\n    const errorType = event.error_event.error_type;\n    const message =\n      event.error_event.message || event.error_event.reason || \"Unknown error\";\n\n    if (errorType === \"max_duration_exceeded\") {\n      this.endSessionWithDetails({\n        reason: \"error\",\n        message: message,\n        context: new Event(\"max_duration_exceeded\"),\n      });\n      return;\n    }\n\n    this.onError(`Server error: ${message}`, {\n      errorType,\n      code: event.error_event.code,\n      debugMessage: event.error_event.debug_message,\n      details: event.error_event.details,\n    });\n  }\n\n  private onMessage = async (parsedEvent: IncomingSocketEvent) => {\n    switch (parsedEvent.type) {\n      case \"interruption\": {\n        this.handleInterruption(parsedEvent);\n        return;\n      }\n      case \"agent_response\": {\n        this.handleAgentResponse(parsedEvent);\n        return;\n      }\n      case \"user_transcript\": {\n        this.handleUserTranscript(parsedEvent);\n        return;\n      }\n      case \"internal_tentative_agent_response\": {\n        this.handleTentativeAgentResponse(parsedEvent);\n        return;\n      }\n      case \"client_tool_call\": {\n        try {\n          await this.handleClientToolCall(parsedEvent);\n        } catch (error) {\n          this.onError(\n            `Unexpected error in client tool call handling: ${error instanceof Error ? error.message : String(error)}`,\n            {\n              clientToolName: parsedEvent.client_tool_call.tool_name,\n              toolCallId: parsedEvent.client_tool_call.tool_call_id,\n            }\n          );\n        }\n        return;\n      }\n      case \"audio\": {\n        this.handleAudio(parsedEvent);\n        return;\n      }\n\n      case \"vad_score\": {\n        this.handleVadScore(parsedEvent);\n        return;\n      }\n\n      case \"ping\": {\n        this.connection.sendMessage({\n          type: \"pong\",\n          event_id: parsedEvent.ping_event.event_id,\n        });\n        // parsedEvent.ping_event.ping_ms can be used on client side, for example\n        // to warn if ping is too high that experience might be degraded.\n        return;\n      }\n\n      case \"mcp_tool_call\": {\n        this.handleMCPToolCall(parsedEvent);\n        return;\n      }\n\n      case \"mcp_connection_status\": {\n        this.handleMCPConnectionStatus(parsedEvent);\n        return;\n      }\n\n      case \"agent_tool_response\": {\n        this.handleAgentToolResponse(parsedEvent);\n        return;\n      }\n\n      case \"conversation_initiation_metadata\": {\n        this.handleConversationMetadata(parsedEvent);\n        return;\n      }\n\n      case \"asr_initiation_metadata\": {\n        this.handleAsrInitiationMetadata(parsedEvent);\n        return;\n      }\n\n      case \"agent_chat_response_part\": {\n        this.handleAgentChatResponsePart(parsedEvent);\n        return;\n      }\n\n      case \"error\": {\n        this.handleErrorEvent(parsedEvent);\n        return;\n      }\n\n      default: {\n        if (this.options.onDebug) {\n          this.options.onDebug(parsedEvent);\n        }\n        return;\n      }\n    }\n  };\n\n  private onError(message: string, context?: any) {\n    console.error(message, context);\n    if (this.options.onError) {\n      this.options.onError(message, context);\n    }\n  }\n\n  public getId() {\n    return this.connection.conversationId;\n  }\n\n  public isOpen() {\n    return this.status === \"connected\";\n  }\n\n  public setVolume = ({ volume }: { volume: number }) => {\n    this.volume = volume;\n  };\n\n  public setMicMuted(isMuted: boolean) {\n    this.connection.setMicMuted(isMuted);\n  }\n\n  public getInputByteFrequencyData(): Uint8Array {\n    return EMPTY_FREQUENCY_DATA;\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array {\n    return EMPTY_FREQUENCY_DATA;\n  }\n\n  public getInputVolume() {\n    return 0;\n  }\n\n  public getOutputVolume() {\n    return 0;\n  }\n\n  public sendFeedback(like: boolean) {\n    if (!this.canSendFeedback) {\n      console.warn(\n        this.lastFeedbackEventId === 0\n          ? \"Cannot send feedback: the conversation has not started yet.\"\n          : \"Cannot send feedback: feedback has already been sent for the current response.\"\n      );\n      return;\n    }\n\n    this.connection.sendMessage({\n      type: \"feedback\",\n      score: like ? \"like\" : \"dislike\",\n      event_id: this.currentEventId,\n    });\n    this.lastFeedbackEventId = this.currentEventId;\n    this.updateCanSendFeedback();\n  }\n\n  public sendContextualUpdate(text: string) {\n    this.connection.sendMessage({\n      type: \"contextual_update\",\n      text,\n    });\n  }\n\n  public sendUserMessage(text: string) {\n    this.connection.sendMessage({\n      type: \"user_message\",\n      text,\n    });\n  }\n\n  public sendUserActivity() {\n    this.connection.sendMessage({\n      type: \"user_activity\",\n    });\n  }\n\n  public sendMCPToolApprovalResult(toolCallId: string, isApproved: boolean) {\n    this.connection.sendMessage({\n      type: \"mcp_tool_approval_result\",\n      tool_call_id: toolCallId,\n      is_approved: isApproved,\n    });\n  }\n}\n","import type { IncomingSocketEvent, OutgoingSocketEvent } from \"./events\";\nimport type { Mode } from \"../BaseConversation\";\nimport type { ConversationConfigOverrideAgentLanguage as Language } from \"@elevenlabs/types/generated/types/asyncapi-types\";\nimport type { DisconnectionDetails } from \"@elevenlabs/types\";\n\nexport type {\n  DisconnectionDetails,\n  ConversationConfigOverrideAgentLanguage as Language,\n} from \"@elevenlabs/types\";\n\nexport type DelayConfig = {\n  default: number;\n  android?: number;\n  ios?: number;\n};\n\nexport type FormatConfig = {\n  format: \"pcm\" | \"ulaw\";\n  sampleRate: number;\n  outputDeviceId?: string;\n};\n\nexport type OnDisconnectCallback = (details: DisconnectionDetails) => void;\nexport type OnMessageCallback = (event: IncomingSocketEvent) => void;\n\nexport type BaseSessionConfig = {\n  origin?: string;\n  authorization?: string;\n  livekitUrl?: string;\n  overrides?: {\n    agent?: {\n      prompt?: {\n        prompt?: string;\n      };\n      firstMessage?: string;\n      language?: Language;\n    };\n    tts?: {\n      voiceId?: string;\n    };\n    conversation?: {\n      textOnly?: boolean;\n    };\n    client?: {\n      source?: string;\n      version?: string;\n    };\n  };\n  customLlmExtraBody?: unknown;\n  dynamicVariables?: Record<string, string | number | boolean>;\n  useWakeLock?: boolean;\n  connectionDelay?: DelayConfig;\n  textOnly?: boolean;\n  userId?: string;\n};\n\nexport type ConnectionType = \"websocket\" | \"webrtc\";\n\nexport type PublicSessionConfig = BaseSessionConfig & {\n  agentId: string;\n  connectionType: ConnectionType;\n  signedUrl?: never;\n  conversationToken?: never;\n};\n\nexport type PrivateWebSocketSessionConfig = BaseSessionConfig & {\n  signedUrl: string;\n  connectionType?: \"websocket\";\n  agentId?: never;\n  conversationToken?: never;\n};\n\nexport type PrivateWebRTCSessionConfig = BaseSessionConfig & {\n  conversationToken: string;\n  connectionType?: \"webrtc\";\n  agentId?: never;\n  signedUrl?: never;\n};\n\n// Union type for all possible session configurations\nexport type SessionConfig =\n  | PublicSessionConfig\n  | PrivateWebSocketSessionConfig\n  | PrivateWebRTCSessionConfig;\n\nexport abstract class BaseConnection {\n  public abstract readonly conversationId: string;\n  public abstract readonly inputFormat: FormatConfig;\n  public abstract readonly outputFormat: FormatConfig;\n\n  protected queue: IncomingSocketEvent[] = [];\n  protected disconnectionDetails: DisconnectionDetails | null = null;\n  protected onDisconnectCallback: OnDisconnectCallback | null = null;\n  protected onMessageCallback: OnMessageCallback | null = null;\n  protected onModeChangeCallback: ((mode: Mode) => void) | null = null;\n  protected onDebug?: (info: unknown) => void;\n\n  constructor(config: { onDebug?: (info: unknown) => void } = {}) {\n    this.onDebug = config.onDebug;\n  }\n\n  protected debug(info: unknown) {\n    if (this.onDebug) this.onDebug(info);\n  }\n\n  public abstract close(): void;\n  public abstract sendMessage(message: OutgoingSocketEvent): void;\n  public abstract setMicMuted(isMuted: boolean): Promise<void>;\n\n  public onMessage(callback: OnMessageCallback) {\n    this.onMessageCallback = callback;\n    const queue = this.queue;\n    this.queue = [];\n\n    if (queue.length > 0) {\n      // Make sure the queue is flushed after the constructors finishes and\n      // classes are initialized.\n      queueMicrotask(() => {\n        queue.forEach(callback);\n      });\n    }\n  }\n\n  public onDisconnect(callback: OnDisconnectCallback) {\n    this.onDisconnectCallback = callback;\n    const details = this.disconnectionDetails;\n    if (details) {\n      // Make sure the event is triggered after the constructors finishes and\n      // classes are initialized.\n      queueMicrotask(() => {\n        callback(details);\n      });\n    }\n  }\n\n  public onModeChange(callback: (mode: Mode) => void) {\n    this.onModeChangeCallback = callback;\n  }\n\n  protected updateMode(mode: Mode) {\n    this.onModeChangeCallback?.(mode);\n  }\n\n  protected disconnect(details: DisconnectionDetails) {\n    if (!this.disconnectionDetails) {\n      this.disconnectionDetails = details;\n      this.onDisconnectCallback?.(details);\n    }\n  }\n\n  protected handleMessage(parsedEvent: IncomingSocketEvent) {\n    if (this.onMessageCallback) {\n      this.onMessageCallback(parsedEvent);\n    } else {\n      this.queue.push(parsedEvent);\n    }\n  }\n}\n\nexport function parseFormat(format: string): FormatConfig {\n  const [formatPart, sampleRatePart] = format.split(\"_\");\n  if (![\"pcm\", \"ulaw\"].includes(formatPart)) {\n    throw new Error(`Invalid format: ${format}`);\n  }\n\n  const sampleRate = Number.parseInt(sampleRatePart);\n  if (Number.isNaN(sampleRate)) {\n    throw new Error(`Invalid sample rate: ${sampleRatePart}`);\n  }\n\n  return {\n    format: formatPart as FormatConfig[\"format\"],\n    sampleRate,\n  };\n}\n","// This file is auto-generated during build\nexport const PACKAGE_VERSION = \"0.11.0\";\n","import { Outgoing } from \"@elevenlabs/types\";\nimport {\n  AgentChatResponsePartClientEvent,\n  AgentResponse,\n  AgentResponseCorrection,\n  AgentToolResponseClientEvent,\n  AsrInitiationMetadataEvent as AsrMetadataEvent,\n  Audio,\n  ClientToolCallMessage,\n  ConversationMetadata,\n  ErrorMessage,\n  Interruption,\n  McpConnectionStatusClientEvent,\n  McpToolCall,\n  Ping,\n  InternalTentativeAgentResponse as TentativeAgentResponseInternal,\n  UserTranscript,\n  VadScore,\n} from \"@elevenlabs/types/generated/types/asyncapi-types\";\n\n// Compatibility layer - incoming events\nexport type UserTranscriptionEvent = UserTranscript;\nexport type AgentResponseEvent = AgentResponse;\nexport type AgentAudioEvent = Audio;\nexport type InterruptionEvent = Interruption;\nexport type InternalTentativeAgentResponseEvent =\n  TentativeAgentResponseInternal;\nexport type ConfigEvent = ConversationMetadata;\nexport type PingEvent = Ping;\nexport type ClientToolCallEvent = ClientToolCallMessage;\nexport type VadScoreEvent = VadScore;\nexport type MCPToolCallClientEvent = McpToolCall;\nexport type AgentResponseCorrectionEvent = AgentResponseCorrection;\nexport type AgentToolResponseEvent = AgentToolResponseClientEvent;\nexport type ConversationMetadataEvent = ConversationMetadata;\nexport type AsrInitiationMetadataEvent = AsrMetadataEvent;\nexport type MCPConnectionStatusEvent = McpConnectionStatusClientEvent;\nexport type AgentChatResponsePartEvent = AgentChatResponsePartClientEvent;\nexport type ErrorMessageEvent = ErrorMessage;\n\nexport type IncomingSocketEvent =\n  | UserTranscriptionEvent\n  | AgentResponseEvent\n  | AgentResponseCorrectionEvent\n  | AgentAudioEvent\n  | InterruptionEvent\n  | InternalTentativeAgentResponseEvent\n  | ConfigEvent\n  | PingEvent\n  | ClientToolCallEvent\n  | VadScoreEvent\n  | MCPToolCallClientEvent\n  | AgentToolResponseEvent\n  | ConversationMetadataEvent\n  | AsrInitiationMetadataEvent\n  | MCPConnectionStatusEvent\n  | AgentChatResponsePartEvent\n  | ErrorMessageEvent;\n\n// Compatibility layer - outgoing events\nexport type PongEvent = Outgoing.PongClientToOrchestratorEvent;\nexport type UserAudioEvent = Outgoing.UserAudio;\nexport type UserFeedbackEvent = Outgoing.UserFeedbackClientToOrchestratorEvent;\nexport type ClientToolResultEvent =\n  Outgoing.ClientToolResultClientToOrchestratorEvent;\nexport type InitiationClientDataEvent =\n  Outgoing.ConversationInitiationClientToOrchestratorEvent;\nexport type ContextualUpdateEvent =\n  Outgoing.ContextualUpdateClientToOrchestratorEvent;\nexport type UserMessageEvent = Outgoing.UserMessageClientToOrchestratorEvent;\nexport type UserActivityEvent = Outgoing.UserActivityClientToOrchestratorEvent;\nexport type MCPToolApprovalResultEvent =\n  Outgoing.McpToolApprovalResultClientToOrchestratorEvent;\n\nexport type OutgoingSocketEvent =\n  | PongEvent\n  | UserAudioEvent\n  | InitiationClientDataEvent\n  | UserFeedbackEvent\n  | ClientToolResultEvent\n  | ContextualUpdateEvent\n  | UserMessageEvent\n  | UserActivityEvent\n  | MCPToolApprovalResultEvent;\n\nexport function isValidSocketEvent(event: any): event is IncomingSocketEvent {\n  return !!event.type;\n}\n","import type { SessionConfig } from \"./BaseConnection\";\nimport type { InitiationClientDataEvent } from \"./events\";\n\nexport const CONVERSATION_INITIATION_CLIENT_DATA_TYPE =\n  \"conversation_initiation_client_data\";\n\nexport function constructOverrides(\n  config: SessionConfig\n): InitiationClientDataEvent {\n  const overridesEvent: InitiationClientDataEvent = {\n    type: CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n  };\n\n  if (config.overrides) {\n    overridesEvent.conversation_config_override = {\n      agent: {\n        prompt: config.overrides.agent?.prompt,\n        first_message: config.overrides.agent?.firstMessage,\n        language: config.overrides.agent?.language,\n      },\n      tts: {\n        voice_id: config.overrides.tts?.voiceId,\n      },\n      conversation: {\n        text_only: config.overrides.conversation?.textOnly,\n      },\n    };\n  }\n\n  if (config.customLlmExtraBody) {\n    overridesEvent.custom_llm_extra_body = config.customLlmExtraBody;\n  }\n\n  if (config.dynamicVariables) {\n    overridesEvent.dynamic_variables = config.dynamicVariables;\n  }\n\n  if (config.userId) {\n    overridesEvent.user_id = config.userId;\n  }\n\n  if (config.overrides?.client) {\n    overridesEvent.source_info = {\n      source: config.overrides.client.source,\n      version: config.overrides.client.version,\n    };\n  }\n\n  return overridesEvent;\n}\n","import {\n  BaseConnection,\n  type SessionConfig,\n  type FormatConfig,\n  parseFormat,\n} from \"./BaseConnection\";\nimport { PACKAGE_VERSION } from \"../version\";\nimport {\n  type ConfigEvent,\n  isValidSocketEvent,\n  type OutgoingSocketEvent,\n} from \"./events\";\nimport { constructOverrides } from \"./overrides\";\n\nconst MAIN_PROTOCOL = \"convai\";\nconst WSS_API_ORIGIN = \"wss://api.elevenlabs.io\";\nconst WSS_API_PATHNAME = \"/v1/convai/conversation?agent_id=\";\n\nexport class WebSocketConnection extends BaseConnection {\n  public readonly conversationId: string;\n  public readonly inputFormat: FormatConfig;\n  public readonly outputFormat: FormatConfig;\n\n  private constructor(\n    private readonly socket: WebSocket,\n    conversationId: string,\n    inputFormat: FormatConfig,\n    outputFormat: FormatConfig\n  ) {\n    super();\n    this.conversationId = conversationId;\n    this.inputFormat = inputFormat;\n    this.outputFormat = outputFormat;\n\n    this.socket.addEventListener(\"error\", event => {\n      // In case the error event is followed by a close event, we want the\n      // latter to be the one that disconnects the session as it contains more\n      // useful information.\n      setTimeout(\n        () =>\n          this.disconnect({\n            reason: \"error\",\n            message: \"The connection was closed due to a socket error.\",\n            context: event,\n          }),\n        0\n      );\n    });\n\n    this.socket.addEventListener(\"close\", event => {\n      this.disconnect(\n        event.code === 1000\n          ? {\n              reason: \"agent\",\n              context: event,\n            }\n          : {\n              reason: \"error\",\n              message:\n                event.reason || \"The connection was closed by the server.\",\n              context: event,\n            }\n      );\n    });\n\n    this.socket.addEventListener(\"message\", event => {\n      try {\n        const parsedEvent = JSON.parse(event.data);\n        if (!isValidSocketEvent(parsedEvent)) {\n          this.debug({\n            type: \"invalid_event\",\n            message: \"Received invalid socket event\",\n            data: event.data,\n          });\n          return;\n        }\n        this.handleMessage(parsedEvent);\n      } catch (error) {\n        this.debug({\n          type: \"parsing_error\",\n          message: \"Failed to parse socket message\",\n          error: error instanceof Error ? error.message : String(error),\n          data: event.data,\n        });\n      }\n    });\n  }\n\n  public static async create(\n    config: SessionConfig\n  ): Promise<WebSocketConnection> {\n    let socket: WebSocket | null = null;\n\n    try {\n      const origin = config.origin ?? WSS_API_ORIGIN;\n      let url: string;\n\n      const version = config.overrides?.client?.version || PACKAGE_VERSION;\n      const source = config.overrides?.client?.source || \"js_sdk\";\n\n      if (config.signedUrl) {\n        const separator = config.signedUrl.includes(\"?\") ? \"&\" : \"?\";\n        url = `${config.signedUrl}${separator}source=${source}&version=${version}`;\n      } else {\n        url = `${origin}${WSS_API_PATHNAME}${config.agentId}&source=${source}&version=${version}`;\n      }\n\n      const protocols = [MAIN_PROTOCOL];\n      if (config.authorization) {\n        protocols.push(`bearer.${config.authorization}`);\n      }\n      socket = new WebSocket(url, protocols);\n\n      const conversationConfig = await new Promise<\n        ConfigEvent[\"conversation_initiation_metadata_event\"]\n      >((resolve, reject) => {\n        socket!.addEventListener(\n          \"open\",\n          () => {\n            const overridesEvent = constructOverrides(config);\n\n            socket?.send(JSON.stringify(overridesEvent));\n          },\n          { once: true }\n        );\n\n        socket!.addEventListener(\"error\", event => {\n          // In case the error event is followed by a close event, we want the\n          // latter to be the one that rejects the promise as it contains more\n          // useful information.\n          setTimeout(() => reject(event), 0);\n        });\n\n        socket!.addEventListener(\"close\", reject);\n\n        socket!.addEventListener(\n          \"message\",\n          (event: MessageEvent) => {\n            const message = JSON.parse(event.data);\n\n            if (!isValidSocketEvent(message)) {\n              return;\n            }\n\n            if (message.type === \"conversation_initiation_metadata\") {\n              resolve(message.conversation_initiation_metadata_event);\n            } else {\n              console.warn(\n                \"First received message is not conversation metadata.\"\n              );\n            }\n          },\n          { once: true }\n        );\n      });\n\n      const {\n        conversation_id,\n        agent_output_audio_format,\n        user_input_audio_format,\n      } = conversationConfig;\n\n      const inputFormat = parseFormat(user_input_audio_format ?? \"pcm_16000\");\n      const outputFormat = parseFormat(agent_output_audio_format);\n\n      return new WebSocketConnection(\n        socket,\n        conversation_id,\n        inputFormat,\n        outputFormat\n      );\n    } catch (error) {\n      socket?.close();\n      throw error;\n    }\n  }\n\n  public close() {\n    this.socket.close();\n  }\n\n  public sendMessage(message: OutgoingSocketEvent) {\n    this.socket.send(JSON.stringify(message));\n  }\n\n  public async setMicMuted(isMuted: boolean): Promise<void> {\n    console.warn(\n      `WebSocket connection setMicMuted called with ${isMuted}, but this is handled by VoiceConversation`\n    );\n  }\n}\n","export function arrayBufferToBase64(b: ArrayBufferLike) {\n  const buffer = new Uint8Array(b);\n  // @ts-ignore\n  const base64Data = window.btoa(String.fromCharCode(...buffer));\n  return base64Data;\n}\n\nexport function base64ToArrayBuffer(base64: string): ArrayBuffer {\n  const binaryString = window.atob(base64);\n  const len = binaryString.length;\n  const bytes = new Uint8Array(len);\n  for (let i = 0; i < len; i++) {\n    bytes[i] = binaryString.charCodeAt(i);\n  }\n  return bytes.buffer;\n}\n","const URLCache = new Map<string, string>();\n\nexport function createWorkletModuleLoader(name: string, sourceCode: string) {\n  return async (worklet: AudioWorklet, path?: string) => {\n    const cachedUrl = URLCache.get(name);\n    if (cachedUrl) {\n      return worklet.addModule(cachedUrl);\n    }\n\n    // If a path is provided, use it directly (CSP-friendly approach)\n    if (path) {\n      try {\n        await worklet.addModule(path);\n        URLCache.set(name, path);\n        return;\n      } catch (error) {\n        throw new Error(\n          `Failed to load the ${name} worklet module from path: ${path}. Error: ${error}`\n        );\n      }\n    }\n\n    const blob = new Blob([sourceCode], { type: \"application/javascript\" });\n    const blobURL = URL.createObjectURL(blob);\n    try {\n      await worklet.addModule(blobURL);\n      URLCache.set(name, blobURL);\n      return;\n    } catch {\n      URL.revokeObjectURL(blobURL);\n    }\n\n    try {\n      // Attempting to start a conversation in Safari inside an iframe will\n      // throw a CORS error because the blob:// protocol is considered\n      // cross-origin. In such cases, fall back to using a base64 data URL:\n      const base64 = btoa(sourceCode);\n      const moduleURL = `data:application/javascript;base64,${base64}`;\n      await worklet.addModule(moduleURL);\n      URLCache.set(name, moduleURL);\n    } catch (error) {\n      throw new Error(\n        `Failed to load the ${name} worklet module. Make sure the browser supports AudioWorklets. If you are using a strict CSP, you may need to self-host the worklet files.`\n      );\n    }\n  };\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadRawAudioProcessor = createWorkletModuleLoader(\n  \"rawAudioProcessor\",\n  // language=JavaScript\n  `/*\n * ulaw encoding logic taken from the wavefile library\n * https://github.com/rochars/wavefile/blob/master/lib/codecs/mulaw.js\n * USED BY @elevenlabs/client\n */\n\nconst BIAS = 0x84;\nconst CLIP = 32635;\nconst encodeTable = [\n  0,0,1,1,2,2,2,2,3,3,3,3,3,3,3,3,\n  4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,\n  5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n  5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7\n];\n\nfunction encodeSample(sample) {\n  let sign;\n  let exponent;\n  let mantissa;\n  let muLawSample;\n  sign = (sample >> 8) & 0x80;\n  if (sign !== 0) sample = -sample;\n  sample = sample + BIAS;\n  if (sample > CLIP) sample = CLIP;\n  exponent = encodeTable[(sample>>7) & 0xFF];\n  mantissa = (sample >> (exponent+3)) & 0x0F;\n  muLawSample = ~(sign | (exponent << 4) | mantissa);\n  \n  return muLawSample;\n}\n\nclass RawAudioProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n              \n    this.port.onmessage = ({ data }) => {\n      switch (data.type) {\n        case \"setFormat\":\n          this.isMuted = false;\n          this.buffer = []; // Initialize an empty buffer\n          this.bufferSize = data.sampleRate / 4;\n          this.format = data.format;\n\n          if (globalThis.LibSampleRate && sampleRate !== data.sampleRate) {\n            globalThis.LibSampleRate.create(1, sampleRate, data.sampleRate).then(resampler => {\n              this.resampler = resampler;\n            });\n          }\n          break;\n        case \"setMuted\":\n          this.isMuted = data.isMuted;\n          break;\n      }\n    };\n  }\n  process(inputs) {\n    if (!this.buffer) {\n      return true;\n    }\n    \n    const input = inputs[0]; // Get the first input node\n    if (input.length > 0) {\n      let channelData = input[0]; // Get the first channel's data\n\n      // Resample the audio if necessary\n      if (this.resampler) {\n        channelData = this.resampler.full(channelData);\n      }\n\n      // Add channel data to the buffer\n      this.buffer.push(...channelData);\n      // Get max volume \n      let sum = 0.0;\n      for (let i = 0; i < channelData.length; i++) {\n        sum += channelData[i] * channelData[i];\n      }\n      const maxVolume = Math.sqrt(sum / channelData.length);\n      // Check if buffer size has reached or exceeded the threshold\n      if (this.buffer.length >= this.bufferSize) {\n        const float32Array = this.isMuted \n          ? new Float32Array(this.buffer.length)\n          : new Float32Array(this.buffer);\n\n        let encodedArray = this.format === \"ulaw\"\n          ? new Uint8Array(float32Array.length)\n          : new Int16Array(float32Array.length);\n\n        // Iterate through the Float32Array and convert each sample to PCM16\n        for (let i = 0; i < float32Array.length; i++) {\n          // Clamp the value to the range [-1, 1]\n          let sample = Math.max(-1, Math.min(1, float32Array[i]));\n\n          // Scale the sample to the range [-32768, 32767]\n          let value = sample < 0 ? sample * 32768 : sample * 32767;\n          if (this.format === \"ulaw\") {\n            value = encodeSample(Math.round(value));\n          }\n\n          encodedArray[i] = value;\n        }\n\n        // Send the buffered data to the main script\n        this.port.postMessage([encodedArray, maxVolume]);\n\n        // Clear the buffer after sending\n        this.buffer = [];\n      }\n    }\n    return true; // Continue processing\n  }\n}\nregisterProcessor(\"rawAudioProcessor\", RawAudioProcessor);\n`\n);\n","import {\n  BaseConnection,\n  type SessionConfig,\n  type FormatConfig,\n  parseFormat,\n} from \"./BaseConnection\";\nimport { PACKAGE_VERSION } from \"../version\";\nimport { isValidSocketEvent, type OutgoingSocketEvent } from \"./events\";\nimport {\n  Room,\n  RoomEvent,\n  Track,\n  ConnectionState,\n  createLocalAudioTrack,\n} from \"livekit-client\";\nimport type {\n  RemoteAudioTrack,\n  Participant,\n  TrackPublication,\n} from \"livekit-client\";\nimport {\n  constructOverrides,\n  CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n} from \"./overrides\";\nimport { arrayBufferToBase64 } from \"./audio\";\nimport { loadRawAudioProcessor } from \"./rawAudioProcessor.generated\";\n\nconst DEFAULT_LIVEKIT_WS_URL = \"wss://livekit.rtc.elevenlabs.io\";\nconst HTTPS_API_ORIGIN = \"https://api.elevenlabs.io\";\n\n// Convert WSS origin to HTTPS for API calls\nfunction convertWssToHttps(origin: string): string {\n  return origin.replace(/^wss:\\/\\//, \"https://\");\n}\n\nexport type ConnectionConfig = SessionConfig & {\n  onDebug?: (info: unknown) => void;\n};\n\nexport class WebRTCConnection extends BaseConnection {\n  public conversationId: string;\n  public readonly inputFormat: FormatConfig;\n  public readonly outputFormat: FormatConfig;\n\n  private room: Room;\n  private isConnected = false;\n  private audioEventId = 1;\n  private audioCaptureContext: AudioContext | null = null;\n  private audioElements: HTMLAudioElement[] = [];\n  private outputDeviceId: string | null = null;\n\n  private outputAnalyser: AnalyserNode | null = null;\n  private outputFrequencyData: Uint8Array<ArrayBuffer> | null = null;\n\n  private constructor(\n    room: Room,\n    conversationId: string,\n    inputFormat: FormatConfig,\n    outputFormat: FormatConfig,\n    config: { onDebug?: (info: unknown) => void } = {}\n  ) {\n    super(config);\n    this.room = room;\n    this.conversationId = conversationId;\n    this.inputFormat = inputFormat;\n    this.outputFormat = outputFormat;\n\n    this.setupRoomEventListeners();\n  }\n\n  public static async create(\n    config: ConnectionConfig\n  ): Promise<WebRTCConnection> {\n    let conversationToken: string;\n\n    // Handle different authentication scenarios\n    if (\"conversationToken\" in config && config.conversationToken) {\n      // Direct token provided\n      conversationToken = config.conversationToken;\n    } else if (\"agentId\" in config && config.agentId) {\n      // Agent ID provided - fetch token from API\n      try {\n        const version = config.overrides?.client?.version || PACKAGE_VERSION;\n        const source = config.overrides?.client?.source || \"js_sdk\";\n        const configOrigin = config.origin ?? HTTPS_API_ORIGIN;\n        const origin = convertWssToHttps(configOrigin); //origin is wss, not https\n        const url = `${origin}/v1/convai/conversation/token?agent_id=${config.agentId}&source=${source}&version=${version}`;\n        const response = await fetch(url);\n\n        if (!response.ok) {\n          throw new Error(\n            `ElevenLabs API returned ${response.status} ${response.statusText}`\n          );\n        }\n\n        const data = await response.json();\n        conversationToken = data.token;\n\n        if (!conversationToken) {\n          throw new Error(\"No conversation token received from API\");\n        }\n      } catch (error) {\n        let msg = error instanceof Error ? error.message : String(error);\n        if (error instanceof Error && error.message.includes(\"401\")) {\n          msg =\n            \"Your agent has authentication enabled, but no signed URL or conversation token was provided.\";\n        }\n\n        throw new Error(\n          `Failed to fetch conversation token for agent ${config.agentId}: ${msg}`\n        );\n      }\n    } else {\n      throw new Error(\n        \"Either conversationToken or agentId is required for WebRTC connection\"\n      );\n    }\n\n    const room = new Room();\n\n    try {\n      // Create connection instance first to set up event listeners\n      const conversationId = `room_${Date.now()}`;\n      const inputFormat = parseFormat(\"pcm_48000\");\n      const outputFormat = parseFormat(\"pcm_48000\");\n      const connection = new WebRTCConnection(\n        room,\n        conversationId,\n        inputFormat,\n        outputFormat,\n        config\n      );\n\n      // Use configurable LiveKit URL or default if not provided\n      const livekitUrl = config.livekitUrl || DEFAULT_LIVEKIT_WS_URL;\n\n      // Connect to the LiveKit room and wait for the Connected event\n      await room.connect(livekitUrl, conversationToken);\n\n      // Wait for the Connected event to ensure isConnected is true\n      await new Promise<void>(resolve => {\n        if (connection.isConnected) {\n          resolve();\n        } else {\n          const onConnected = () => {\n            room.off(RoomEvent.Connected, onConnected);\n            resolve();\n          };\n          room.on(RoomEvent.Connected, onConnected);\n        }\n      });\n\n      if (room.name) {\n        connection.conversationId =\n          room.name.match(/(conv_[a-zA-Z0-9]+)/)?.[0] || room.name;\n      }\n\n      // Enable microphone and send overrides\n      await room.localParticipant.setMicrophoneEnabled(true);\n\n      const overridesEvent = constructOverrides(config);\n\n      connection.debug({\n        type: CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n        message: overridesEvent,\n      });\n\n      await connection.sendMessage(overridesEvent);\n\n      return connection;\n    } catch (error) {\n      await room.disconnect();\n      throw error;\n    }\n  }\n\n  private setupRoomEventListeners() {\n    this.room.on(RoomEvent.Connected, async () => {\n      this.isConnected = true;\n      console.info(\"WebRTC room connected\");\n    });\n\n    this.room.on(RoomEvent.Disconnected, reason => {\n      this.isConnected = false;\n      this.disconnect({\n        reason: \"agent\",\n        context: new CloseEvent(\"close\", { reason: reason?.toString() }),\n      });\n    });\n\n    this.room.on(RoomEvent.ConnectionStateChanged, state => {\n      if (state === ConnectionState.Disconnected) {\n        this.isConnected = false;\n        this.disconnect({\n          reason: \"error\",\n          message: `LiveKit connection state changed to ${state}`,\n          context: new Event(\"connection_state_changed\"),\n        });\n      }\n    });\n\n    // Handle incoming data messages\n    this.room.on(\n      RoomEvent.DataReceived,\n      (payload: Uint8Array, _participant) => {\n        try {\n          const message = JSON.parse(new TextDecoder().decode(payload));\n\n          // Filter out audio messages for WebRTC - they're handled via audio tracks\n          if (message.type === \"audio\") {\n            return;\n          }\n\n          if (isValidSocketEvent(message)) {\n            this.handleMessage(message);\n          } else {\n            console.warn(\"Invalid socket event received:\", message);\n          }\n        } catch (error) {\n          console.warn(\"Failed to parse incoming data message:\", error);\n          console.warn(\"Raw payload:\", new TextDecoder().decode(payload));\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.TrackSubscribed,\n      async (\n        track: Track,\n        _publication: TrackPublication,\n        participant: Participant\n      ) => {\n        if (\n          track.kind === Track.Kind.Audio &&\n          participant.identity.includes(\"agent\")\n        ) {\n          // Play the audio track\n          const remoteAudioTrack = track as RemoteAudioTrack;\n          const audioElement = remoteAudioTrack.attach();\n          audioElement.autoplay = true;\n          audioElement.controls = false;\n\n          // Set output device if one was previously selected\n          if (this.outputDeviceId && audioElement.setSinkId) {\n            try {\n              await audioElement.setSinkId(this.outputDeviceId);\n            } catch (error) {\n              console.warn(\n                \"Failed to set output device for new audio element:\",\n                error\n              );\n            }\n          }\n\n          // Add to DOM (hidden) to ensure it plays\n          audioElement.style.display = \"none\";\n          document.body.appendChild(audioElement);\n\n          // Store reference for volume control\n          this.audioElements.push(audioElement);\n\n          // Apply current volume if it exists (for when volume was set before audio track arrived)\n          if (this.audioElements.length === 1) {\n            // First audio element - trigger a callback to sync with current volume\n            this.onDebug?.({ type: \"audio_element_ready\" });\n          }\n\n          // Set up audio capture for onAudio callback\n          await this.setupAudioCapture(remoteAudioTrack);\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.ActiveSpeakersChanged,\n      async (speakers: Participant[]) => {\n        if (speakers.length > 0) {\n          this.updateMode(\n            speakers[0].identity.startsWith(\"agent\") ? \"speaking\" : \"listening\"\n          );\n        } else {\n          this.updateMode(\"listening\");\n        }\n      }\n    );\n  }\n\n  public close() {\n    if (this.isConnected) {\n      try {\n        // Explicitly stop all local tracks before disconnecting to ensure microphone is released\n        this.room.localParticipant.audioTrackPublications.forEach(\n          publication => {\n            if (publication.track) {\n              publication.track.stop();\n            }\n          }\n        );\n      } catch (error) {\n        console.warn(\"Error stopping local tracks:\", error);\n      }\n\n      // Clean up audio capture context (non-blocking)\n      if (this.audioCaptureContext) {\n        this.audioCaptureContext.close().catch(error => {\n          console.warn(\"Error closing audio capture context:\", error);\n        });\n        this.audioCaptureContext = null;\n      }\n\n      // Clean up audio elements\n      this.audioElements.forEach(element => {\n        if (element.parentNode) {\n          element.parentNode.removeChild(element);\n        }\n      });\n      this.audioElements = [];\n\n      this.room.disconnect();\n    }\n  }\n\n  public async sendMessage(message: OutgoingSocketEvent) {\n    if (!this.isConnected || !this.room.localParticipant) {\n      console.warn(\n        \"Cannot send message: room not connected or no local participant\"\n      );\n      return;\n    }\n\n    // In WebRTC mode, audio is sent via published tracks, not data messages\n    if (\"user_audio_chunk\" in message) {\n      // Ignore audio data messages - audio flows through WebRTC tracks\n      return;\n    }\n\n    try {\n      const encoder = new TextEncoder();\n      const data = encoder.encode(JSON.stringify(message));\n\n      await this.room.localParticipant.publishData(data, { reliable: true });\n    } catch (error) {\n      this.debug({\n        type: \"send_message_error\",\n        message: {\n          message,\n          error,\n        },\n      });\n      console.error(\"Failed to send message via WebRTC:\", error);\n    }\n  }\n\n  // Get the room instance for advanced usage\n  public getRoom(): Room {\n    return this.room;\n  }\n\n  public async setMicMuted(isMuted: boolean): Promise<void> {\n    if (!this.isConnected || !this.room.localParticipant) {\n      console.warn(\n        \"Cannot set microphone muted: room not connected or no local participant\"\n      );\n      return;\n    }\n\n    // Get the microphone track publication\n    const micTrackPublication = this.room.localParticipant.getTrackPublication(\n      Track.Source.Microphone\n    );\n\n    if (micTrackPublication?.track) {\n      try {\n        // Use LiveKit's built-in track muting\n        if (isMuted) {\n          await micTrackPublication.track.mute();\n        } else {\n          await micTrackPublication.track.unmute();\n        }\n      } catch (_error) {\n        // If track muting fails, fall back to participant-level control\n        await this.room.localParticipant.setMicrophoneEnabled(!isMuted);\n      }\n    } else {\n      // No track found, use participant-level control directly\n      await this.room.localParticipant.setMicrophoneEnabled(!isMuted);\n    }\n  }\n\n  private async setupAudioCapture(track: RemoteAudioTrack) {\n    try {\n      // Create audio context for processing\n      const audioContext = new AudioContext();\n      this.audioCaptureContext = audioContext;\n\n      // Create analyser for frequency data\n      this.outputAnalyser = audioContext.createAnalyser();\n      this.outputAnalyser.fftSize = 2048;\n      this.outputAnalyser.smoothingTimeConstant = 0.8;\n\n      // Create MediaStream from the track\n      const mediaStream = new MediaStream([track.mediaStreamTrack]);\n\n      // Create audio source from the stream\n      const source = audioContext.createMediaStreamSource(mediaStream);\n\n      // Connect source to analyser\n      source.connect(this.outputAnalyser);\n\n      await loadRawAudioProcessor(audioContext.audioWorklet);\n      const worklet = new AudioWorkletNode(audioContext, \"rawAudioProcessor\");\n\n      // Connect analyser to worklet for processing\n      this.outputAnalyser.connect(worklet);\n\n      // Configure the processor for the output format\n      worklet.port.postMessage({\n        type: \"setFormat\",\n        format: this.outputFormat.format,\n        sampleRate: this.outputFormat.sampleRate,\n      });\n\n      // Handle processed audio data\n      worklet.port.onmessage = (event: MessageEvent) => {\n        const [audioData, maxVolume] = event.data;\n\n        // Only send audio if there's significant volume (not just silence)\n        const volumeThreshold = 0.01;\n\n        if (maxVolume > volumeThreshold) {\n          // Convert to base64\n          const base64Audio = arrayBufferToBase64(audioData.buffer);\n\n          // Use sequential event ID for proper feedback tracking\n          const eventId = this.audioEventId++;\n\n          // Trigger the onAudio callback by simulating an audio event\n          this.handleMessage({\n            type: \"audio\",\n            audio_event: {\n              audio_base_64: base64Audio,\n              event_id: eventId,\n            },\n          });\n        }\n      };\n\n      // Connect the audio processing chain\n      source.connect(worklet);\n    } catch (error) {\n      console.warn(\"Failed to set up audio capture:\", error);\n    }\n  }\n\n  public setAudioVolume(volume: number) {\n    this.audioElements.forEach(element => {\n      element.volume = volume;\n    });\n  }\n\n  public async setAudioOutputDevice(deviceId: string): Promise<void> {\n    if (!(\"setSinkId\" in HTMLAudioElement.prototype)) {\n      throw new Error(\"setSinkId is not supported in this browser\");\n    }\n\n    // Set output device for all existing audio elements\n    const promises = this.audioElements.map(async element => {\n      try {\n        await element.setSinkId(deviceId);\n      } catch (error) {\n        console.error(\"Failed to set sink ID for audio element:\", error);\n        throw error;\n      }\n    });\n\n    await Promise.all(promises);\n\n    // Store the device ID for future audio elements\n    this.outputDeviceId = deviceId;\n  }\n\n  public async setAudioInputDevice(deviceId: string): Promise<void> {\n    if (!this.isConnected || !this.room.localParticipant) {\n      throw new Error(\n        \"Cannot change input device: room not connected or no local participant\"\n      );\n    }\n\n    try {\n      // Get the current microphone track publication\n      const currentMicTrackPublication =\n        this.room.localParticipant.getTrackPublication(Track.Source.Microphone);\n\n      // Stop the current microphone track if it exists\n      if (currentMicTrackPublication?.track) {\n        await currentMicTrackPublication.track.stop();\n        await this.room.localParticipant.unpublishTrack(\n          currentMicTrackPublication.track\n        );\n      }\n\n      // Create constraints for the new input device\n      const audioConstraints: MediaTrackConstraints = {\n        deviceId: { exact: deviceId },\n        echoCancellation: true,\n        noiseSuppression: true,\n        autoGainControl: true,\n        channelCount: { ideal: 1 },\n      };\n\n      // Create new audio track with the specified device\n      const audioTrack = await createLocalAudioTrack(audioConstraints);\n\n      // Publish the new microphone track\n      await this.room.localParticipant.publishTrack(audioTrack, {\n        name: \"microphone\",\n        source: Track.Source.Microphone,\n      });\n    } catch (error) {\n      console.error(\"Failed to change input device:\", error);\n\n      // Try to re-enable default microphone on failure\n      try {\n        await this.room.localParticipant.setMicrophoneEnabled(true);\n      } catch (recoveryError) {\n        console.error(\n          \"Failed to recover microphone after device switch error:\",\n          recoveryError\n        );\n      }\n\n      throw error;\n    }\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array<ArrayBuffer> | null {\n    if (!this.outputAnalyser) return null;\n\n    this.outputFrequencyData ??= new Uint8Array(\n      this.outputAnalyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.outputAnalyser.getByteFrequencyData(this.outputFrequencyData);\n    return this.outputFrequencyData;\n  }\n}\n","import type {\n  BaseConnection,\n  SessionConfig,\n  ConnectionType,\n} from \"./BaseConnection\";\nimport { WebSocketConnection } from \"./WebSocketConnection\";\nimport { WebRTCConnection } from \"./WebRTCConnection\";\n\nfunction determineConnectionType(config: SessionConfig): ConnectionType {\n  // If connectionType is explicitly specified, use it\n  if (config.connectionType) {\n    return config.connectionType;\n  }\n\n  // If conversationToken is provided, use WebRTC\n  if (\"conversationToken\" in config && config.conversationToken) {\n    return \"webrtc\";\n  }\n\n  // Default to WebSocket for backward compatibility\n  return \"websocket\";\n}\n\nexport async function createConnection(\n  config: SessionConfig\n): Promise<BaseConnection> {\n  const connectionType = determineConnectionType(config);\n\n  switch (connectionType) {\n    case \"websocket\":\n      return WebSocketConnection.create(config);\n    case \"webrtc\":\n      return WebRTCConnection.create(config);\n    default:\n      throw new Error(`Unknown connection type: ${connectionType}`);\n  }\n}\n","export function isIosDevice() {\n  return (\n    [\n      \"iPad Simulator\",\n      \"iPhone Simulator\",\n      \"iPod Simulator\",\n      \"iPad\",\n      \"iPhone\",\n      \"iPod\",\n    ].includes(navigator.platform) ||\n    // iPad on iOS 13 detection\n    (navigator.userAgent.includes(\"Mac\") && \"ontouchend\" in document)\n  );\n}\n\nexport function isAndroidDevice() {\n  return /android/i.test(navigator.userAgent);\n}\n","import { isAndroidDevice, isIosDevice } from \"./compatibility\";\nimport type { DelayConfig } from \"./connection\";\n\nexport async function applyDelay(\n  delayConfig: DelayConfig = {\n    default: 0,\n    // Give the Android AudioManager enough time to switch to the correct audio mode\n    android: 3_000,\n  }\n) {\n  let delay = delayConfig.default;\n  if (isAndroidDevice()) {\n    delay = delayConfig.android ?? delay;\n  } else if (isIosDevice()) {\n    delay = delayConfig.ios ?? delay;\n  }\n\n  if (delay > 0) {\n    await new Promise(resolve => setTimeout(resolve, delay));\n  }\n}\n","import { createConnection } from \"./utils/ConnectionFactory\";\nimport type { BaseConnection } from \"./utils/BaseConnection\";\nimport { applyDelay } from \"./utils/applyDelay\";\nimport { BaseConversation, type PartialOptions } from \"./BaseConversation\";\n\nexport class TextConversation extends BaseConversation {\n  public static async startSession(\n    options: PartialOptions\n  ): Promise<TextConversation> {\n    const fullOptions = BaseConversation.getFullOptions(options);\n\n    if (fullOptions.onStatusChange) {\n      fullOptions.onStatusChange({ status: \"connecting\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n    if (fullOptions.onModeChange) {\n      fullOptions.onModeChange({ mode: \"listening\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n\n    let connection: BaseConnection | null = null;\n    try {\n      await applyDelay(fullOptions.connectionDelay);\n      connection = await createConnection(options);\n      return new TextConversation(fullOptions, connection);\n    } catch (error) {\n      if (fullOptions.onStatusChange) {\n        fullOptions.onStatusChange({ status: \"disconnected\" });\n      }\n      connection?.close();\n      throw error;\n    }\n  }\n}\n","import { loadRawAudioProcessor } from \"./rawAudioProcessor.generated\";\nimport type { FormatConfig } from \"./connection\";\nimport { isIosDevice } from \"./compatibility\";\nimport type { AudioWorkletConfig } from \"../BaseConversation\";\n\nexport type InputConfig = {\n  preferHeadphonesForIosDevices?: boolean;\n  inputDeviceId?: string;\n};\n\nconst LIBSAMPLERATE_JS =\n  \"https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js\";\n\nconst defaultConstraints = {\n  echoCancellation: true,\n  noiseSuppression: true,\n  // Automatic gain control helps maintain a steady volume level with microphones: https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackSettings/autoGainControl\n  autoGainControl: true,\n  // Mono audio for better echo cancellation\n  channelCount: { ideal: 1 },\n};\n\nexport class Input {\n  public static async create({\n    sampleRate,\n    format,\n    preferHeadphonesForIosDevices,\n    inputDeviceId,\n    workletPaths,\n    libsampleratePath,\n  }: FormatConfig & InputConfig & AudioWorkletConfig): Promise<Input> {\n    let context: AudioContext | null = null;\n    let inputStream: MediaStream | null = null;\n\n    try {\n      const options: MediaTrackConstraints = {\n        sampleRate: { ideal: sampleRate },\n        ...defaultConstraints,\n      };\n\n      if (isIosDevice() && preferHeadphonesForIosDevices) {\n        const availableDevices =\n          await window.navigator.mediaDevices.enumerateDevices();\n        const idealDevice = availableDevices.find(\n          d =>\n            // cautious to include \"bluetooth\" in the search\n            // as might trigger bluetooth speakers\n            d.kind === \"audioinput\" &&\n            [\"airpod\", \"headphone\", \"earphone\"].find(keyword =>\n              d.label.toLowerCase().includes(keyword)\n            )\n        );\n        if (idealDevice) {\n          options.deviceId = { ideal: idealDevice.deviceId };\n        }\n      }\n\n      if (inputDeviceId) {\n        options.deviceId = { exact: inputDeviceId };\n      }\n\n      const supportsSampleRateConstraint =\n        navigator.mediaDevices.getSupportedConstraints().sampleRate;\n\n      context = new window.AudioContext(\n        supportsSampleRateConstraint ? { sampleRate } : {}\n      );\n      const analyser = context.createAnalyser();\n      if (!supportsSampleRateConstraint) {\n        // Use custom libsamplerate path if provided, otherwise fallback to CDN\n        const libsamplerateUrl = libsampleratePath || LIBSAMPLERATE_JS;\n        await context.audioWorklet.addModule(libsamplerateUrl);\n      }\n      await loadRawAudioProcessor(\n        context.audioWorklet,\n        workletPaths?.[\"rawAudioProcessor\"]\n      );\n\n      const constraints = { voiceIsolation: true, ...options };\n      inputStream = await navigator.mediaDevices.getUserMedia({\n        audio: constraints,\n      });\n\n      const source = context.createMediaStreamSource(inputStream);\n      const worklet = new AudioWorkletNode(context, \"rawAudioProcessor\");\n      worklet.port.postMessage({ type: \"setFormat\", format, sampleRate });\n\n      source.connect(analyser);\n      analyser.connect(worklet);\n\n      await context.resume();\n\n      return new Input(context, analyser, worklet, inputStream, source);\n    } catch (error) {\n      inputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      context?.close();\n      throw error;\n    }\n  }\n\n  private constructor(\n    public readonly context: AudioContext,\n    public readonly analyser: AnalyserNode,\n    public readonly worklet: AudioWorkletNode,\n    public inputStream: MediaStream,\n    private mediaStreamSource: MediaStreamAudioSourceNode\n  ) {}\n\n  public async close() {\n    this.inputStream.getTracks().forEach(track => {\n      track.stop();\n    });\n    this.mediaStreamSource.disconnect();\n    await this.context.close();\n  }\n\n  public setMuted(isMuted: boolean) {\n    this.worklet.port.postMessage({ type: \"setMuted\", isMuted });\n  }\n\n  public async setInputDevice(inputDeviceId?: string): Promise<void> {\n    try {\n      // Create new constraints with the specified device or use default\n      const options: MediaTrackConstraints = {\n        ...defaultConstraints,\n      };\n\n      if (inputDeviceId) {\n        options.deviceId = { exact: inputDeviceId };\n      }\n      // If inputDeviceId is undefined, don't set deviceId constraint - browser uses default\n\n      const constraints = { voiceIsolation: true, ...options };\n\n      // Get new media stream with the specified device\n      const newInputStream = await navigator.mediaDevices.getUserMedia({\n        audio: constraints,\n      });\n\n      // Stop old tracks and disconnect old source\n      this.inputStream.getTracks().forEach(track => {\n        track.stop();\n      });\n      this.mediaStreamSource.disconnect();\n\n      // Replace the stream and create new source\n      this.inputStream = newInputStream;\n      this.mediaStreamSource =\n        this.context.createMediaStreamSource(newInputStream);\n\n      // Reconnect the audio graph\n      this.mediaStreamSource.connect(this.analyser);\n    } catch (error) {\n      console.error(\"Failed to switch input device:\", error);\n      throw error;\n    }\n  }\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadAudioConcatProcessor = createWorkletModuleLoader(\n  \"audioConcatProcessor\",\n  // language=JavaScript\n  `/*\n * ulaw decoding logic taken from the wavefile library\n * https://github.com/rochars/wavefile/blob/master/lib/codecs/mulaw.js\n * USED BY @elevenlabs/client\n */\n\nconst decodeTable = [0,132,396,924,1980,4092,8316,16764];\n\nfunction decodeSample(muLawSample) {\n  let sign;\n  let exponent;\n  let mantissa;\n  let sample;\n  muLawSample = ~muLawSample;\n  sign = (muLawSample & 0x80);\n  exponent = (muLawSample >> 4) & 0x07;\n  mantissa = muLawSample & 0x0F;\n  sample = decodeTable[exponent] + (mantissa << (exponent+3));\n  if (sign !== 0) sample = -sample;\n\n  return sample;\n}\n\nclass AudioConcatProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.buffers = []; // Initialize an empty buffer\n    this.cursor = 0;\n    this.currentBuffer = null;\n    this.wasInterrupted = false;\n    this.finished = false;\n    \n    this.port.onmessage = ({ data }) => {\n      switch (data.type) {\n        case \"setFormat\":\n          this.format = data.format;\n          break;\n        case \"buffer\":\n          this.wasInterrupted = false;\n          this.buffers.push(\n            this.format === \"ulaw\"\n              ? new Uint8Array(data.buffer)\n              : new Int16Array(data.buffer)\n          );\n          break;\n        case \"interrupt\":\n          this.wasInterrupted = true;\n          break;\n        case \"clearInterrupted\":\n          if (this.wasInterrupted) {\n            this.wasInterrupted = false;\n            this.buffers = [];\n            this.currentBuffer = null;\n          }\n      }\n    };\n  }\n  process(_, outputs) {\n    let finished = false;\n    const output = outputs[0][0];\n    for (let i = 0; i < output.length; i++) {\n      if (!this.currentBuffer) {\n        if (this.buffers.length === 0) {\n          finished = true;\n          break;\n        }\n        this.currentBuffer = this.buffers.shift();\n        this.cursor = 0;\n      }\n\n      let value = this.currentBuffer[this.cursor];\n      if (this.format === \"ulaw\") {\n        value = decodeSample(value);\n      }\n      output[i] = value / 32768;\n      this.cursor++;\n\n      if (this.cursor >= this.currentBuffer.length) {\n        this.currentBuffer = null;\n      }\n    }\n\n    if (this.finished !== finished) {\n      this.finished = finished;\n      this.port.postMessage({ type: \"process\", finished });\n    }\n\n    return true; // Continue processing\n  }\n}\n\nregisterProcessor(\"audioConcatProcessor\", AudioConcatProcessor);\n`\n);\n","import { loadAudioConcatProcessor } from \"./audioConcatProcessor.generated\";\nimport type { FormatConfig } from \"./connection\";\nimport type { AudioWorkletConfig } from \"../BaseConversation\";\n\nexport type OutputConfig = {\n  outputDeviceId?: string;\n};\n\nexport class Output {\n  public static async create({\n    sampleRate,\n    format,\n    outputDeviceId,\n    workletPaths,\n  }: FormatConfig & OutputConfig & AudioWorkletConfig): Promise<Output> {\n    let context: AudioContext | null = null;\n    let audioElement: HTMLAudioElement | null = null;\n    try {\n      context = new AudioContext({ sampleRate });\n      const analyser = context.createAnalyser();\n      const gain = context.createGain();\n\n      // Always create an audio element for device switching capability\n      audioElement = new Audio();\n      audioElement.src = \"\";\n      audioElement.load();\n      audioElement.autoplay = true;\n      audioElement.style.display = \"none\";\n\n      document.body.appendChild(audioElement);\n\n      // Create media stream destination to route audio to the element\n      const destination = context.createMediaStreamDestination();\n      audioElement.srcObject = destination.stream;\n\n      gain.connect(analyser);\n      analyser.connect(destination);\n\n      await loadAudioConcatProcessor(\n        context.audioWorklet,\n        workletPaths?.[\"audioConcatProcessor\"]\n      );\n      const worklet = new AudioWorkletNode(context, \"audioConcatProcessor\");\n      worklet.port.postMessage({ type: \"setFormat\", format });\n      worklet.connect(gain);\n\n      await context.resume();\n\n      // Set initial output device if provided\n      if (outputDeviceId && audioElement.setSinkId) {\n        await audioElement.setSinkId(outputDeviceId);\n      }\n\n      const newOutput = new Output(\n        context,\n        analyser,\n        gain,\n        worklet,\n        audioElement\n      );\n\n      return newOutput;\n    } catch (error) {\n      // Clean up audio element from DOM\n      if (audioElement?.parentNode) {\n        audioElement.parentNode.removeChild(audioElement);\n      }\n      audioElement?.pause();\n      if (context && context.state !== \"closed\") {\n        await context.close();\n      }\n\n      throw error;\n    }\n  }\n\n  private constructor(\n    public readonly context: AudioContext,\n    public readonly analyser: AnalyserNode,\n    public readonly gain: GainNode,\n    public readonly worklet: AudioWorkletNode,\n    public readonly audioElement: HTMLAudioElement\n  ) {}\n\n  public async setOutputDevice(deviceId?: string): Promise<void> {\n    if (!(\"setSinkId\" in HTMLAudioElement.prototype)) {\n      throw new Error(\"setSinkId is not supported in this browser\");\n    }\n\n    // If deviceId is undefined, use empty string which resets to default device\n    await this.audioElement.setSinkId(deviceId || \"\");\n  }\n\n  public async close() {\n    // Remove audio element from DOM\n    if (this.audioElement.parentNode) {\n      this.audioElement.parentNode.removeChild(this.audioElement);\n    }\n    this.audioElement.pause();\n    await this.context.close();\n  }\n}\n","import { arrayBufferToBase64, base64ToArrayBuffer } from \"./utils/audio\";\nimport { Input, type InputConfig } from \"./utils/input\";\nimport { Output } from \"./utils/output\";\nimport { createConnection } from \"./utils/ConnectionFactory\";\nimport type { BaseConnection, FormatConfig } from \"./utils/BaseConnection\";\nimport { WebRTCConnection } from \"./utils/WebRTCConnection\";\nimport type { AgentAudioEvent, InterruptionEvent } from \"./utils/events\";\nimport { applyDelay } from \"./utils/applyDelay\";\nimport {\n  BaseConversation,\n  type Options,\n  type PartialOptions,\n} from \"./BaseConversation\";\nimport { WebSocketConnection } from \"./utils/WebSocketConnection\";\n\nexport class VoiceConversation extends BaseConversation {\n  public static async startSession(\n    options: PartialOptions\n  ): Promise<VoiceConversation> {\n    const fullOptions = BaseConversation.getFullOptions(options);\n\n    if (fullOptions.onStatusChange) {\n      fullOptions.onStatusChange({ status: \"connecting\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n\n    let input: Input | null = null;\n    let connection: BaseConnection | null = null;\n    let output: Output | null = null;\n    let preliminaryInputStream: MediaStream | null = null;\n\n    let wakeLock: WakeLockSentinel | null = null;\n    if (options.useWakeLock ?? true) {\n      try {\n        wakeLock = await navigator.wakeLock.request(\"screen\");\n      } catch (_e) {\n        // Wake Lock is not required for the conversation to work\n      }\n    }\n\n    try {\n      // some browsers won't allow calling getSupportedConstraints or enumerateDevices\n      // before getting approval for microphone access\n      preliminaryInputStream = await navigator.mediaDevices.getUserMedia({\n        audio: true,\n      });\n\n      await applyDelay(fullOptions.connectionDelay);\n      connection = await createConnection(options);\n      [input, output] = await Promise.all([\n        Input.create({\n          ...connection.inputFormat,\n          preferHeadphonesForIosDevices: options.preferHeadphonesForIosDevices,\n          inputDeviceId: options.inputDeviceId,\n          workletPaths: options.workletPaths,\n          libsampleratePath: options.libsampleratePath,\n        }),\n        Output.create({\n          ...connection.outputFormat,\n          outputDeviceId: options.outputDeviceId,\n          workletPaths: options.workletPaths,\n        }),\n      ]);\n\n      preliminaryInputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      preliminaryInputStream = null;\n\n      return new VoiceConversation(\n        fullOptions,\n        connection,\n        input,\n        output,\n        wakeLock\n      );\n    } catch (error) {\n      if (fullOptions.onStatusChange) {\n        fullOptions.onStatusChange({ status: \"disconnected\" });\n      }\n      preliminaryInputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      connection?.close();\n      await input?.close();\n      await output?.close();\n      try {\n        await wakeLock?.release();\n        wakeLock = null;\n      } catch (_e) {}\n      throw error;\n    }\n  }\n\n  private inputFrequencyData?: Uint8Array<ArrayBuffer>;\n  private outputFrequencyData?: Uint8Array<ArrayBuffer>;\n\n  protected constructor(\n    options: Options,\n    connection: BaseConnection,\n    public input: Input,\n    public output: Output,\n    public wakeLock: WakeLockSentinel | null\n  ) {\n    super(options, connection);\n    this.input.worklet.port.onmessage = this.onInputWorkletMessage;\n    this.output.worklet.port.onmessage = this.onOutputWorkletMessage;\n  }\n\n  protected override async handleEndSession() {\n    await super.handleEndSession();\n    try {\n      await this.wakeLock?.release();\n      this.wakeLock = null;\n    } catch (_e) {}\n\n    await this.input.close();\n    await this.output.close();\n  }\n\n  protected override handleInterruption(event: InterruptionEvent) {\n    super.handleInterruption(event);\n    this.fadeOutAudio();\n  }\n\n  protected override handleAudio(event: AgentAudioEvent) {\n    if (this.lastInterruptTimestamp <= event.audio_event.event_id) {\n      this.options.onAudio?.(event.audio_event.audio_base_64);\n\n      // Only play audio through the output worklet for WebSocket connections\n      // WebRTC connections handle audio playback directly through LiveKit tracks\n      if (!(this.connection instanceof WebRTCConnection)) {\n        this.addAudioBase64Chunk(event.audio_event.audio_base_64);\n      }\n\n      this.currentEventId = event.audio_event.event_id;\n      this.updateCanSendFeedback();\n      this.updateMode(\"speaking\");\n    }\n  }\n\n  private onInputWorkletMessage = (event: MessageEvent): void => {\n    const rawAudioPcmData = event.data[0];\n\n    // TODO: When supported, maxVolume can be used to avoid sending silent audio\n    // const maxVolume = event.data[1];\n\n    if (this.status === \"connected\") {\n      this.connection.sendMessage({\n        user_audio_chunk: arrayBufferToBase64(rawAudioPcmData.buffer),\n      });\n    }\n  };\n\n  private onOutputWorkletMessage = ({ data }: MessageEvent): void => {\n    if (data.type === \"process\") {\n      this.updateMode(data.finished ? \"listening\" : \"speaking\");\n    }\n  };\n\n  private addAudioBase64Chunk = (chunk: string) => {\n    this.output.gain.gain.cancelScheduledValues(\n      this.output.context.currentTime\n    );\n    this.output.gain.gain.value = this.volume;\n    this.output.worklet.port.postMessage({ type: \"clearInterrupted\" });\n    this.output.worklet.port.postMessage({\n      type: \"buffer\",\n      buffer: base64ToArrayBuffer(chunk),\n    });\n  };\n\n  private fadeOutAudio = () => {\n    // mute agent\n    this.updateMode(\"listening\");\n    this.output.worklet.port.postMessage({ type: \"interrupt\" });\n    this.output.gain.gain.exponentialRampToValueAtTime(\n      0.0001,\n      this.output.context.currentTime + 2\n    );\n\n    // reset volume back\n    setTimeout(() => {\n      this.output.gain.gain.value = this.volume;\n      this.output.worklet.port.postMessage({ type: \"clearInterrupted\" });\n    }, 2000); // Adjust the duration as needed\n  };\n\n  private calculateVolume = (frequencyData: Uint8Array) => {\n    if (frequencyData.length === 0) {\n      return 0;\n    }\n\n    // TODO: Currently this averages all frequencies, but we should probably\n    // bias towards the frequencies that are more typical for human voice\n    let volume = 0;\n    for (let i = 0; i < frequencyData.length; i++) {\n      volume += frequencyData[i] / 255;\n    }\n    volume /= frequencyData.length;\n\n    return volume < 0 ? 0 : volume > 1 ? 1 : volume;\n  };\n\n  public setMicMuted(isMuted: boolean) {\n    // Use LiveKit track muting for WebRTC connections\n    if (this.connection instanceof WebRTCConnection) {\n      this.connection.setMicMuted(isMuted);\n    } else {\n      // Use input muting for WebSocket connections\n      this.input.setMuted(isMuted);\n    }\n  }\n\n  public getInputByteFrequencyData(): Uint8Array<ArrayBuffer> {\n    this.inputFrequencyData ??= new Uint8Array(\n      this.input.analyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.input.analyser.getByteFrequencyData(this.inputFrequencyData);\n    return this.inputFrequencyData;\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array<ArrayBuffer> {\n    // Use WebRTC analyser if available\n    if (this.connection instanceof WebRTCConnection) {\n      const webrtcData = this.connection.getOutputByteFrequencyData();\n      if (webrtcData) {\n        return webrtcData as Uint8Array<ArrayBuffer>;\n      }\n      // Fallback to empty array if WebRTC analyser not ready\n      return new Uint8Array(1024) as Uint8Array<ArrayBuffer>;\n    }\n\n    this.outputFrequencyData ??= new Uint8Array(\n      this.output.analyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.output.analyser.getByteFrequencyData(this.outputFrequencyData);\n    return this.outputFrequencyData;\n  }\n\n  public getInputVolume() {\n    return this.calculateVolume(this.getInputByteFrequencyData());\n  }\n\n  public getOutputVolume() {\n    return this.calculateVolume(this.getOutputByteFrequencyData());\n  }\n\n  public async changeInputDevice({\n    sampleRate,\n    format,\n    preferHeadphonesForIosDevices,\n    inputDeviceId,\n  }: FormatConfig & InputConfig): Promise<Input> {\n    try {\n      // For WebSocket connections, try to change device on existing input first\n      if (this.connection instanceof WebSocketConnection) {\n        try {\n          await this.input.setInputDevice(inputDeviceId);\n          return this.input;\n        } catch (error) {\n          console.warn(\n            \"Failed to change device on existing input, recreating:\",\n            error\n          );\n          // Fall back to recreating the input\n        }\n      }\n\n      // Handle WebRTC connections differently\n      if (this.connection instanceof WebRTCConnection) {\n        await this.connection.setAudioInputDevice(inputDeviceId || \"\");\n      }\n\n      // Fallback: recreate the input\n      await this.input.close();\n\n      const newInput = await Input.create({\n        sampleRate: sampleRate ?? this.connection.inputFormat.sampleRate,\n        format: format ?? this.connection.inputFormat.format,\n        preferHeadphonesForIosDevices,\n        inputDeviceId,\n        workletPaths: this.options.workletPaths,\n        libsampleratePath: this.options.libsampleratePath,\n      });\n\n      this.input = newInput;\n      this.input.worklet.port.onmessage = this.onInputWorkletMessage;\n\n      return this.input;\n    } catch (error) {\n      console.error(\"Error changing input device\", error);\n      throw error;\n    }\n  }\n\n  public async changeOutputDevice({\n    sampleRate,\n    format,\n    outputDeviceId,\n  }: FormatConfig): Promise<Output> {\n    try {\n      // For WebSocket connections, try to change device on existing output first\n      if (this.connection instanceof WebSocketConnection) {\n        try {\n          await this.output.setOutputDevice(outputDeviceId);\n          return this.output;\n        } catch (error) {\n          console.warn(\n            \"Failed to change device on existing output, recreating:\",\n            error\n          );\n          // Fall back to recreating the output\n        }\n      }\n\n      // Handle WebRTC connections differently\n      if (this.connection instanceof WebRTCConnection) {\n        await this.connection.setAudioOutputDevice(outputDeviceId || \"\");\n      }\n\n      // Fallback: recreate the output\n      await this.output.close();\n\n      const newOutput = await Output.create({\n        sampleRate: sampleRate ?? this.connection.outputFormat.sampleRate,\n        format: format ?? this.connection.outputFormat.format,\n        outputDeviceId,\n        workletPaths: this.options.workletPaths,\n      });\n\n      this.output = newOutput;\n\n      return this.output;\n    } catch (error) {\n      console.error(\"Error changing output device\", error);\n      throw error;\n    }\n  }\n\n  public setVolume = ({ volume }: { volume: number }) => {\n    // clamp & coerce\n    const clampedVolume = Number.isFinite(volume)\n      ? Math.min(1, Math.max(0, volume))\n      : 1;\n    this.volume = clampedVolume;\n\n    if (this.connection instanceof WebRTCConnection) {\n      // For WebRTC connections, control volume via HTML audio elements\n      this.connection.setAudioVolume(clampedVolume);\n    } else {\n      // For WebSocket connections, control volume via gain node\n      this.output.gain.gain.value = clampedVolume;\n    }\n  };\n}\n","const HTTPS_API_ORIGIN = \"https://api.elevenlabs.io\";\n\nexport interface RatingFeedback {\n  rating: number;\n  comment?: string;\n}\n\ntype Feedback = RatingFeedback;\n\nexport function postOverallFeedback(\n  conversationId: string,\n  like: boolean,\n  origin?: string\n): Promise<Response>;\nexport function postOverallFeedback(\n  conversationId: string,\n  feedback: Feedback,\n  origin?: string\n): Promise<Response>;\nexport function postOverallFeedback(\n  conversationId: string,\n  likeOrFeedback: boolean | Feedback,\n  origin: string = HTTPS_API_ORIGIN\n): Promise<Response> {\n  const body: {\n    feedback?: \"like\" | \"dislike\";\n    rating?: number;\n    comment?: string;\n  } = {};\n\n  if (typeof likeOrFeedback === \"boolean\") {\n    body.feedback = likeOrFeedback ? \"like\" : \"dislike\";\n  } else {\n    body.rating = likeOrFeedback.rating;\n    body.comment = likeOrFeedback.comment;\n  }\n\n  return fetch(`${origin}/v1/convai/conversations/${conversationId}/feedback`, {\n    method: \"POST\",\n    body: JSON.stringify(body),\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n  });\n}\n","import type {\n  InputAudioChunk,\n  SessionStartedMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n} from \"@elevenlabs/types\";\n\n// Re-export types for public API\nexport type {\n  SessionStartedMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n};\n\nexport type WebSocketMessage =\n  | SessionStartedMessage\n  | PartialTranscriptMessage\n  | CommittedTranscriptMessage\n  | CommittedTranscriptWithTimestampsMessage\n  | ScribeErrorMessage\n  | ScribeAuthErrorMessage\n  | ScribeQuotaExceededErrorMessage;\n\n/**\n * Simple EventEmitter implementation for browser compatibility.\n */\nclass EventEmitter {\n  private listeners: Map<string, Set<(...args: unknown[]) => void>> = new Map();\n\n  on(event: string, listener: (...args: unknown[]) => void): void {\n    if (!this.listeners.has(event)) {\n      this.listeners.set(event, new Set());\n    }\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.add(listener);\n    }\n  }\n\n  off(event: string, listener: (...args: unknown[]) => void): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.delete(listener);\n    }\n  }\n\n  emit(event: string, ...args: unknown[]): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.forEach(listener => {\n        listener(...args);\n      });\n    }\n  }\n}\n\n/**\n * Events emitted by the RealtimeConnection.\n */\nexport enum RealtimeEvents {\n  /** Emitted when the session is successfully started */\n  SESSION_STARTED = \"session_started\",\n  /** Emitted when a partial (interim) transcript is available */\n  PARTIAL_TRANSCRIPT = \"partial_transcript\",\n  /** Emitted when a final transcript is available */\n  COMMITTED_TRANSCRIPT = \"committed_transcript\",\n  /** Emitted when a final transcript with timestamps is available */\n  COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS = \"committed_transcript_with_timestamps\",\n  /** Emitted when an authentication error occurs */\n  AUTH_ERROR = \"auth_error\",\n  /** Emitted when an error occurs */\n  ERROR = \"error\",\n  /** Emitted when the WebSocket connection is opened */\n  OPEN = \"open\",\n  /** Emitted when the WebSocket connection is closed */\n  CLOSE = \"close\",\n  /** Emitted when a quota exceeded error occurs */\n  QUOTA_EXCEEDED = \"quota_exceeded\",\n}\n\n/**\n * Manages a real-time transcription WebSocket connection.\n *\n * @example\n * ```typescript\n * const connection = await Scribe.connect({\n *     token: \"...\",\n *     modelId: \"scribe_v2_realtime\",\n *     audioFormat: AudioFormat.PCM_16000,\n *     sampleRate: 16000,\n * });\n *\n * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {\n *     console.log(\"Session started\");\n * });\n *\n * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {\n *     console.log(\"Partial:\", data.transcript);\n * });\n *\n * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n *     console.log(\"Final:\", data.transcript);\n *     connection.close();\n * });\n *\n * // Send audio data\n * connection.send({ audioBase64: base64String });\n *\n * // Commit and close\n * connection.commit();\n * ```\n */\nexport class RealtimeConnection {\n  private websocket: WebSocket | null = null;\n  private eventEmitter: EventEmitter = new EventEmitter();\n  private currentSampleRate: number = 16000;\n  public _audioCleanup?: () => void;\n\n  constructor(sampleRate: number) {\n    this.currentSampleRate = sampleRate;\n  }\n\n  /**\n   * @internal\n   * Used internally by ScribeRealtime to attach the WebSocket after connection is created.\n   */\n  public setWebSocket(websocket: WebSocket): void {\n    this.websocket = websocket;\n\n    // If WebSocket is already open, emit OPEN event immediately\n    if (this.websocket.readyState === WebSocket.OPEN) {\n      this.eventEmitter.emit(RealtimeEvents.OPEN);\n    } else {\n      // Otherwise, wait for the open event\n      this.websocket.addEventListener(\"open\", () => {\n        this.eventEmitter.emit(RealtimeEvents.OPEN);\n      });\n    }\n\n    this.websocket.addEventListener(\"message\", (event: MessageEvent) => {\n      try {\n        const data = JSON.parse(event.data) as WebSocketMessage;\n\n        switch (data.message_type) {\n          case \"session_started\":\n            this.eventEmitter.emit(RealtimeEvents.SESSION_STARTED, data);\n            break;\n          case \"partial_transcript\":\n            this.eventEmitter.emit(RealtimeEvents.PARTIAL_TRANSCRIPT, data);\n            break;\n          case \"committed_transcript\":\n            this.eventEmitter.emit(RealtimeEvents.COMMITTED_TRANSCRIPT, data);\n            break;\n          case \"committed_transcript_with_timestamps\":\n            this.eventEmitter.emit(\n              RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS,\n              data\n            );\n            break;\n          case \"auth_error\":\n            this.eventEmitter.emit(RealtimeEvents.AUTH_ERROR, data);\n            break;\n          case \"quota_exceeded\":\n            this.eventEmitter.emit(RealtimeEvents.QUOTA_EXCEEDED, data);\n            break;\n          case \"error\":\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          default:\n            console.warn(\"Unknown message type:\", data);\n        }\n      } catch (error) {\n        console.error(\"Failed to parse WebSocket message:\", error, event.data);\n        this.eventEmitter.emit(\n          RealtimeEvents.ERROR,\n          new Error(`Failed to parse message: ${error}`)\n        );\n      }\n    });\n\n    this.websocket.addEventListener(\"error\", (error: Event) => {\n      console.error(\"WebSocket error:\", error);\n      this.eventEmitter.emit(RealtimeEvents.ERROR, error);\n    });\n\n    this.websocket.addEventListener(\"close\", (event: CloseEvent) => {\n      console.log(\n        `WebSocket closed: code=${event.code}, reason=\"${event.reason}\", wasClean=${event.wasClean}`\n      );\n\n      // Emit error if close was not clean or had an error code\n      if (!event.wasClean || (event.code !== 1000 && event.code !== 1005)) {\n        const errorMessage = `WebSocket closed unexpectedly: ${event.code} - ${event.reason || \"No reason provided\"}`;\n        console.error(errorMessage);\n        this.eventEmitter.emit(RealtimeEvents.ERROR, new Error(errorMessage));\n      }\n\n      this.eventEmitter.emit(RealtimeEvents.CLOSE, event);\n    });\n  }\n\n  /**\n   * Attaches an event listener for the specified event.\n   *\n   * @param event - The event to listen for (use RealtimeEvents enum)\n   * @param listener - The callback function to execute when the event fires\n   *\n   * @example\n   * ```typescript\n   * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {\n   *     console.log(\"Session started\", data);\n   * });\n   *\n   * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {\n   *     console.log(\"Partial:\", data.transcript);\n   * });\n   *\n   * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n   *     console.log(\"Final:\", data.transcript);\n   * });\n   * ```\n   */\n  public on(\n    event: RealtimeEvents,\n    listener: (...args: unknown[]) => void\n  ): void {\n    this.eventEmitter.on(event, listener);\n  }\n\n  /**\n   * Removes an event listener for the specified event.\n   *\n   * @param event - The event to stop listening for\n   * @param listener - The callback function to remove\n   *\n   * @example\n   * ```typescript\n   * const handler = (data) => console.log(data);\n   * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);\n   *\n   * // Later, remove the listener\n   * connection.off(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);\n   * ```\n   */\n  public off(\n    event: RealtimeEvents,\n    listener: (...args: unknown[]) => void\n  ): void {\n    this.eventEmitter.off(event, listener);\n  }\n\n  /**\n   * Sends audio data to the transcription service.\n   *\n   * @param data - Audio data configuration\n   * @param data.audioBase64 - Base64-encoded audio data\n   * @param data.commit - Whether to commit the transcription after this chunk. You likely want to use connection.commit() instead (default: false)\n   * @param data.sampleRate - Sample rate of the audio (default: configured sample rate)\n   *\n   * @throws {Error} If the WebSocket connection is not open\n   *\n   * @example\n   * ```typescript\n   * // Send audio chunk without committing\n   * connection.send({\n   *     audioBase64: base64EncodedAudio,\n   * });\n   *\n   * // Send audio chunk with custom sample rate\n   * connection.send({\n   *     audioBase64: base64EncodedAudio,\n   *     sampleRate: 16000,\n   * });\n   * ```\n   */\n  public send(data: {\n    audioBase64: string;\n    commit?: boolean;\n    sampleRate?: number;\n  }): void {\n    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {\n      throw new Error(\"WebSocket is not connected\");\n    }\n\n    const message: InputAudioChunk = {\n      message_type: \"input_audio_chunk\",\n      audio_base_64: data.audioBase64,\n      commit: data.commit ?? false,\n      sample_rate: data.sampleRate ?? this.currentSampleRate,\n    };\n\n    this.websocket.send(JSON.stringify(message));\n  }\n\n  /**\n   * Commits the transcription, signaling that a segment of audio has been sent. This clears the buffer and triggers a COMMITTED_TRANSCRIPT event. Context from previous segments is kept.\n   * Committing a segment triggers a COMMITTED_TRANSCRIPT event.\n   *\n   * @throws {Error} If the WebSocket connection is not open\n   *\n   * @remarks\n   * Only needed when using CommitStrategy.MANUAL.\n   * When using CommitStrategy.VAD, commits are handled automatically by the server.\n   *\n   * @example\n   * ```typescript\n   * // Send all audio chunks\n   * for (const chunk of audioChunks) {\n   *     connection.send({ audioBase64: chunk });\n   * }\n   *\n   * // Finalize the transcription\n   * connection.commit();\n   * ```\n   */\n  public commit(): void {\n    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {\n      throw new Error(\"WebSocket is not connected\");\n    }\n\n    const message: InputAudioChunk = {\n      message_type: \"input_audio_chunk\",\n      audio_base_64: \"\",\n      commit: true,\n      sample_rate: this.currentSampleRate,\n    };\n\n    this.websocket.send(JSON.stringify(message));\n  }\n\n  /**\n   * Closes the WebSocket connection and cleans up resources.\n   * This will terminate any ongoing transcription and stop microphone streaming if active.\n   *\n   * @remarks\n   * After calling close(), this connection cannot be reused.\n   * Create a new connection if you need to start transcribing again.\n   *\n   * @example\n   * ```typescript\n   * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n   *     console.log(\"Segment committed:\", data.transcript);\n   *     connection.close();\n   * });\n   * ```\n   */\n  public close(): void {\n    // Cleanup audio resources (microphone stream, audio context)\n    if (this._audioCleanup) {\n      this._audioCleanup();\n    }\n\n    // Close WebSocket connection\n    if (this.websocket) {\n      this.websocket.close();\n    }\n  }\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadScribeAudioProcessor = createWorkletModuleLoader(\n  \"scribeAudioProcessor\",\n  // language=JavaScript\n  `/*\n * Scribe Audio Processor for converting microphone audio to PCM16 format\n * USED BY @elevenlabs/client\n */\n\nclass ScribeAudioProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.buffer = [];\n    this.bufferSize = 4096; // Buffer size for optimal chunk transmission\n  }\n\n  process(inputs) {\n    const input = inputs[0];\n    if (input.length > 0) {\n      const channelData = input[0]; // Get first channel (mono)\n\n      // Add incoming audio to buffer\n      this.buffer.push(...channelData);\n\n      // When buffer reaches threshold, convert and send\n      if (this.buffer.length >= this.bufferSize) {\n        const float32Array = new Float32Array(this.buffer);\n        const int16Array = new Int16Array(float32Array.length);\n\n        // Convert Float32 [-1, 1] to Int16 [-32768, 32767]\n        for (let i = 0; i < float32Array.length; i++) {\n          // Clamp the value to prevent overflow\n          const sample = Math.max(-1, Math.min(1, float32Array[i]));\n          // Scale to PCM16 range\n          int16Array[i] = sample < 0 ? sample * 32768 : sample * 32767;\n        }\n\n        // Send to main thread as transferable ArrayBuffer\n        this.port.postMessage(\n          {\n            audioData: int16Array.buffer\n          },\n          [int16Array.buffer]\n        );\n\n        // Clear buffer\n        this.buffer = [];\n      }\n    }\n\n    return true; // Continue processing\n  }\n}\n\nregisterProcessor(\"scribeAudioProcessor\", ScribeAudioProcessor);\n\n`\n);\n","import { RealtimeConnection } from \"./connection\";\nimport { loadScribeAudioProcessor } from \"../utils/scribeAudioProcessor.generated\";\n\nexport enum AudioFormat {\n  PCM_8000 = \"pcm_8000\",\n  PCM_16000 = \"pcm_16000\",\n  PCM_22050 = \"pcm_22050\",\n  PCM_24000 = \"pcm_24000\",\n  PCM_44100 = \"pcm_44100\",\n  PCM_48000 = \"pcm_48000\",\n  ULAW_8000 = \"ulaw_8000\",\n}\n\nexport enum CommitStrategy {\n  MANUAL = \"manual\",\n  VAD = \"vad\",\n}\n\ninterface BaseOptions {\n  /**\n   * Token to use for the WebSocket connection. Obtained from the ElevenLabs API.\n   */\n  token: string;\n  /**\n   * Strategy for committing transcriptions.\n   * @default CommitStrategy.MANUAL\n   */\n  commitStrategy?: CommitStrategy;\n  /**\n   * Silence threshold in seconds for VAD (Voice Activity Detection).\n   * Must be a positive number between 0.3 and 3.0\n   */\n  vadSilenceThresholdSecs?: number;\n  /**\n   * Threshold for voice activity detection.\n   * Must be between 0.1 and 0.9.\n   */\n  vadThreshold?: number;\n  /**\n   * Minimum speech duration in milliseconds.\n   * Must be a positive integer between 50 and 2000.\n   */\n  minSpeechDurationMs?: number;\n  /**\n   * Minimum silence duration in milliseconds.\n   * Must be a positive integer between 50 and 2000.\n   */\n  minSilenceDurationMs?: number;\n  /**\n   * Model ID to use for transcription.\n   * Must be a valid model ID.\n   */\n  modelId: string;\n  /**\n   * An ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file.\n   * Can sometimes improve transcription performance if known beforehand.\n   */\n  languageCode?: string;\n  /**\n   * Base URI to use for the WebSocket connection.\n   * If not provided, the default URI will be used.\n   */\n  baseUri?: string;\n  /**\n   * Whether to receive a committed_transcript_with_timestamps event which includes word-level timestamps.\n   * @default false\n   */\n  includeTimestamps?: boolean;\n}\n\nexport interface AudioOptions extends BaseOptions {\n  audioFormat: AudioFormat;\n  sampleRate: number;\n  microphone?: never;\n}\n\n/**\n * Options for automatic microphone streaming in the browser.\n */\nexport interface MicrophoneOptions extends BaseOptions {\n  microphone?: {\n    deviceId?: string;\n    echoCancellation?: boolean;\n    noiseSuppression?: boolean;\n    autoGainControl?: boolean;\n    channelCount?: number;\n  };\n  audioFormat?: never;\n  sampleRate?: never;\n}\n\n/**\n * Real-time speech-to-text transcription client for browser environments.\n * Supports microphone streaming and manual audio chunk transmission.\n */\n\n// biome-ignore lint/complexity/noStaticOnlyClass: This class is static only because it is a singleton\nexport class ScribeRealtime {\n  private static readonly DEFAULT_BASE_URI = \"wss://api.elevenlabs.io\";\n\n  private static getWebSocketUri(\n    baseUri: string = ScribeRealtime.DEFAULT_BASE_URI\n  ): string {\n    return `${baseUri}/v1/speech-to-text/realtime`;\n  }\n\n  private static buildWebSocketUri(\n    options: AudioOptions | MicrophoneOptions\n  ): string {\n    const baseUri = ScribeRealtime.getWebSocketUri(options.baseUri);\n    const params = new URLSearchParams();\n\n    // Model ID is required, so no check required\n    params.append(\"model_id\", options.modelId);\n\n    params.append(\"token\", options.token);\n\n    // Add optional parameters if provided, with validation\n    if (options.commitStrategy !== undefined) {\n      params.append(\"commit_strategy\", options.commitStrategy);\n    }\n    if (options.vadSilenceThresholdSecs !== undefined) {\n      if (\n        options.vadSilenceThresholdSecs <= 0.3 ||\n        options.vadSilenceThresholdSecs > 3.0\n      ) {\n        throw new Error(\"vadSilenceThresholdSecs must be between 0.3 and 3.0\");\n      }\n      params.append(\n        \"vad_silence_threshold_secs\",\n        options.vadSilenceThresholdSecs.toString()\n      );\n    }\n    if (options.vadThreshold !== undefined) {\n      if (options.vadThreshold < 0.1 || options.vadThreshold > 0.9) {\n        throw new Error(\"vadThreshold must be between 0.1 and 0.9\");\n      }\n      params.append(\"vad_threshold\", options.vadThreshold.toString());\n    }\n    if (options.minSpeechDurationMs !== undefined) {\n      if (\n        options.minSpeechDurationMs <= 50 ||\n        options.minSpeechDurationMs > 2000\n      ) {\n        throw new Error(\"minSpeechDurationMs must be between 50 and 2000\");\n      }\n      params.append(\n        \"min_speech_duration_ms\",\n        options.minSpeechDurationMs.toString()\n      );\n    }\n    if (options.minSilenceDurationMs !== undefined) {\n      if (\n        options.minSilenceDurationMs <= 50 ||\n        options.minSilenceDurationMs > 2000\n      ) {\n        throw new Error(\"minSilenceDurationMs must be between 50 and 2000\");\n      }\n      params.append(\n        \"min_silence_duration_ms\",\n        options.minSilenceDurationMs.toString()\n      );\n    }\n    if (options.languageCode !== undefined) {\n      params.append(\"language_code\", options.languageCode);\n    }\n    if (options.includeTimestamps !== undefined) {\n      params.append(\n        \"include_timestamps\",\n        options.includeTimestamps ? \"true\" : \"false\"\n      );\n    }\n\n    const queryString = params.toString();\n    return queryString ? `${baseUri}?${queryString}` : baseUri;\n  }\n\n  /**\n   * Establishes a WebSocket connection for real-time speech-to-text transcription.\n   *\n   * @param options - Configuration options for the connection\n   * @returns A RealtimeConnection instance\n   *\n   * @example\n   * ```typescript\n   * // Manual audio streaming\n   * const connection = Scribe.connect({\n   *     token: \"...\",\n   *     modelId: \"scribe_v2_realtime\",\n   *     audioFormat: AudioFormat.PCM_16000,\n   *     sampleRate: 16000,\n   * });\n   *\n   * // Automatic microphone streaming\n   * const connection = Scribe.connect({\n   *     token: \"...\",\n   *     modelId: \"scribe_v2_realtime\",\n   *     microphone: {\n   *         echoCancellation: true,\n   *         noiseSuppression: true\n   *     }\n   * });\n   * ```\n   */\n  public static connect(\n    options: AudioOptions | MicrophoneOptions\n  ): RealtimeConnection {\n    if (!options.modelId) {\n      throw new Error(\"modelId is required\");\n    }\n\n    // Create connection object first so users can attach event listeners before messages arrive\n    const sampleRate =\n      \"microphone\" in options && options.microphone\n        ? 16000\n        : (options as AudioOptions).sampleRate;\n    const connection = new RealtimeConnection(sampleRate);\n\n    // Build WebSocket URI with query parameters\n    const uri = ScribeRealtime.buildWebSocketUri(options);\n\n    const websocket = new WebSocket(uri);\n\n    // If microphone mode, set up streaming handler\n    if (\"microphone\" in options && options.microphone) {\n      websocket.addEventListener(\"open\", () => {\n        ScribeRealtime.streamFromMicrophone(\n          options as MicrophoneOptions,\n          connection\n        );\n      });\n    }\n\n    connection.setWebSocket(websocket);\n\n    return connection;\n  }\n\n  private static async streamFromMicrophone(\n    options: MicrophoneOptions,\n    connection: RealtimeConnection\n  ): Promise<void> {\n    try {\n      // Get microphone access\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          deviceId: options.microphone?.deviceId,\n          echoCancellation: options.microphone?.echoCancellation ?? true,\n          noiseSuppression: options.microphone?.noiseSuppression ?? true,\n          autoGainControl: options.microphone?.autoGainControl ?? true,\n          channelCount: options.microphone?.channelCount ?? 1,\n          sampleRate: { ideal: 16000 },\n        },\n      });\n\n      // Create audio context at 16kHz (Scribe's default)\n      const audioContext = new AudioContext({ sampleRate: 16000 });\n\n      // Load scribe worklet\n      await loadScribeAudioProcessor(audioContext.audioWorklet);\n\n      // Set up audio pipeline\n      const source = audioContext.createMediaStreamSource(stream);\n      const workletNode = new AudioWorkletNode(\n        audioContext,\n        \"scribeAudioProcessor\"\n      );\n\n      // Handle audio data from worklet\n      workletNode.port.onmessage = event => {\n        const { audioData } = event.data;\n        // Convert ArrayBuffer to base64\n        const bytes = new Uint8Array(audioData);\n        let binary = \"\";\n        for (let i = 0; i < bytes.length; i++) {\n          binary += String.fromCharCode(bytes[i]);\n        }\n        const base64Audio = btoa(binary);\n\n        connection.send({ audioBase64: base64Audio });\n      };\n\n      // Connect audio pipeline\n      source.connect(workletNode);\n\n      // Resume audio context if needed\n      if (audioContext.state === \"suspended\") {\n        await audioContext.resume();\n      }\n\n      // Store cleanup function\n      connection._audioCleanup = () => {\n        stream.getTracks().forEach(track => {\n          track.stop();\n        });\n        source.disconnect();\n        workletNode.disconnect();\n        audioContext.close();\n      };\n    } catch (error) {\n      console.error(\"Failed to start microphone streaming:\", error);\n      throw error;\n    }\n  }\n}\n","import { BaseConversation, type PartialOptions } from \"./BaseConversation\";\nimport { TextConversation } from \"./TextConversation\";\nimport { VoiceConversation } from \"./VoiceConversation\";\n\nexport type {\n  Mode,\n  Role,\n  Options,\n  PartialOptions,\n  ClientToolsConfig,\n  Callbacks,\n  Status,\n  AudioWorkletConfig,\n} from \"./BaseConversation\";\nexport type { InputConfig } from \"./utils/input\";\nexport type { OutputConfig } from \"./utils/output\";\nexport { Input } from \"./utils/input\";\nexport { Output } from \"./utils/output\";\nexport type { IncomingSocketEvent, VadScoreEvent } from \"./utils/events\";\nexport type {\n  SessionConfig,\n  BaseSessionConfig,\n  DisconnectionDetails,\n  Language,\n  ConnectionType,\n  FormatConfig,\n} from \"./utils/BaseConnection\";\nexport { createConnection } from \"./utils/ConnectionFactory\";\nexport { WebSocketConnection } from \"./utils/WebSocketConnection\";\nexport { WebRTCConnection } from \"./utils/WebRTCConnection\";\nexport { postOverallFeedback } from \"./utils/postOverallFeedback\";\nexport { VoiceConversation } from \"./VoiceConversation\";\nexport { TextConversation } from \"./TextConversation\";\n\n// Scribe exports\nexport {\n  Scribe,\n  AudioFormat,\n  CommitStrategy,\n  RealtimeEvents,\n  RealtimeConnection,\n} from \"./scribe\";\nexport type {\n  AudioOptions,\n  MicrophoneOptions,\n  WebSocketMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n} from \"./scribe\";\n\nexport class Conversation extends BaseConversation {\n  public static startSession(options: PartialOptions): Promise<Conversation> {\n    return options.textOnly\n      ? TextConversation.startSession(options)\n      : VoiceConversation.startSession(options);\n  }\n}\n"],"names":["EMPTY_FREQUENCY_DATA","Uint8Array","BaseConversation","getFullOptions","partialOptions","_extends","clientTools","onConnect","onDebug","onDisconnect","onError","onMessage","onAudio","onModeChange","onStatusChange","onCanSendFeedbackChange","onInterruption","constructor","options","connection","_this","this","lastInterruptTimestamp","mode","status","volume","currentEventId","lastFeedbackEventId","canSendFeedback","endSessionWithDetails","async","details","updateStatus","handleEndSession","parsedEvent","type","handleInterruption","handleAgentResponse","handleUserTranscript","handleTentativeAgentResponse","handleClientToolCall","error","Error","message","String","clientToolName","client_tool_call","tool_name","toolCallId","tool_call_id","handleAudio","handleVadScore","sendMessage","event_id","ping_event","handleMCPToolCall","handleMCPConnectionStatus","handleAgentToolResponse","handleConversationMetadata","handleAsrInitiationMetadata","handleAgentChatResponsePart","handleErrorEvent","setVolume","conversationId","updateMode","endSession","reason","close","updateCanSendFeedback","event","interruption_event","source","agent_response_event","agent_response","user_transcription_event","user_transcript","response","tentative_agent_response_internal_event","tentative_agent_response","onVadScore","vadScore","vad_score_event","vad_score","Object","prototype","hasOwnProperty","call","_await$this$options$c","result","parameters","formattedResult","JSON","stringify","is_error","e","onUnhandledClientToolCall","onMCPToolCall","mcp_tool_call","onMCPConnectionStatus","mcp_connection_status","agent_tool_response","context","CloseEvent","onAgentToolResponse","onConversationMetadata","conversation_initiation_metadata_event","onAsrInitiationMetadata","asr_initiation_metadata_event","onAgentChatResponsePart","text_response_part","errorType","error_event","error_type","code","debugMessage","debug_message","Event","console","getId","isOpen","setMicMuted","isMuted","getInputByteFrequencyData","getOutputByteFrequencyData","getInputVolume","getOutputVolume","sendFeedback","like","score","warn","sendContextualUpdate","text","sendUserMessage","sendUserActivity","sendMCPToolApprovalResult","isApproved","is_approved","BaseConnection","config","queue","disconnectionDetails","onDisconnectCallback","onMessageCallback","onModeChangeCallback","debug","info","callback","length","queueMicrotask","forEach","_this$onModeChangeCal","disconnect","_this$onDisconnectCal","handleMessage","push","parseFormat","format","formatPart","sampleRatePart","split","includes","sampleRate","Number","parseInt","isNaN","PACKAGE_VERSION","isValidSocketEvent","CONVERSATION_INITIATION_CLIENT_DATA_TYPE","constructOverrides","_config$overrides","overridesEvent","_config$overrides$age","_config$overrides$age2","_config$overrides$age3","_config$overrides$tts","_config$overrides$con","overrides","conversation_config_override","agent","prompt","first_message","firstMessage","language","tts","voice_id","voiceId","conversation","text_only","textOnly","customLlmExtraBody","custom_llm_extra_body","dynamicVariables","dynamic_variables","userId","user_id","client","source_info","version","WebSocketConnection","socket","inputFormat","outputFormat","super","addEventListener","setTimeout","parse","data","create","_config$origin","_config$overrides2","origin","url","signedUrl","separator","agentId","protocols","authorization","WebSocket","conversationConfig","Promise","resolve","reject","_socket","send","once","conversation_id","agent_output_audio_format","user_input_audio_format","_socket2","arrayBufferToBase64","b","buffer","window","btoa","fromCharCode","base64ToArrayBuffer","base64","binaryString","atob","len","bytes","i","charCodeAt","URLCache","Map","createWorkletModuleLoader","name","sourceCode","worklet","path","cachedUrl","get","addModule","set","blob","Blob","blobURL","URL","createObjectURL","_unused","revokeObjectURL","moduleURL","loadRawAudioProcessor","WebRTCConnection","room","isConnected","audioEventId","audioCaptureContext","audioElements","outputDeviceId","outputAnalyser","outputFrequencyData","setupRoomEventListeners","conversationToken","replace","fetch","ok","statusText","json","token","msg","Room","Date","now","livekitUrl","_room$name$match","connect","onConnected","off","RoomEvent","Connected","on","match","localParticipant","setMicrophoneEnabled","Disconnected","toString","ConnectionStateChanged","state","ConnectionState","DataReceived","payload","_participant","TextDecoder","decode","TrackSubscribed","track","_publication","participant","kind","Track","Kind","Audio","identity","remoteAudioTrack","audioElement","attach","autoplay","controls","setSinkId","style","display","document","body","appendChild","setupAudioCapture","ActiveSpeakersChanged","speakers","startsWith","audioTrackPublications","publication","stop","catch","element","parentNode","removeChild","TextEncoder","encode","publishData","reliable","getRoom","micTrackPublication","getTrackPublication","Source","Microphone","mute","unmute","_error","audioContext","AudioContext","createAnalyser","fftSize","smoothingTimeConstant","mediaStream","MediaStream","mediaStreamTrack","createMediaStreamSource","audioWorklet","AudioWorkletNode","port","postMessage","onmessage","audioData","maxVolume","base64Audio","eventId","audio_event","audio_base_64","setAudioVolume","setAudioOutputDevice","deviceId","HTMLAudioElement","promises","map","all","setAudioInputDevice","currentMicTrackPublication","unpublishTrack","audioConstraints","exact","echoCancellation","noiseSuppression","autoGainControl","channelCount","ideal","audioTrack","createLocalAudioTrack","publishTrack","recoveryError","frequencyBinCount","getByteFrequencyData","createConnection","connectionType","determineConnectionType","isIosDevice","navigator","platform","userAgent","applyDelay","delayConfig","default","android","delay","_delayConfig$android","test","_delayConfig$ios","ios","TextConversation","startSession","fullOptions","connectionDelay","_connection","defaultConstraints","Input","preferHeadphonesForIosDevices","inputDeviceId","workletPaths","libsampleratePath","inputStream","idealDevice","mediaDevices","enumerateDevices","find","d","keyword","label","toLowerCase","supportsSampleRateConstraint","getSupportedConstraints","analyser","libsamplerateUrl","constraints","voiceIsolation","getUserMedia","audio","resume","_inputStream","_context","getTracks","mediaStreamSource","setMuted","setInputDevice","newInputStream","loadAudioConcatProcessor","Output","gain","createGain","src","load","destination","createMediaStreamDestination","srcObject","stream","_audioElement","_audioElement2","pause","setOutputDevice","VoiceConversation","_options$useWakeLock","input","output","preliminaryInputStream","wakeLock","useWakeLock","request","_e","_preliminaryInputStre","_preliminaryInputStre2","_input","_output","_wakeLock","release","inputFrequencyData","onInputWorkletMessage","user_audio_chunk","onOutputWorkletMessage","finished","addAudioBase64Chunk","chunk","cancelScheduledValues","currentTime","value","fadeOutAudio","exponentialRampToValueAtTime","calculateVolume","frequencyData","clampedVolume","isFinite","Math","min","max","_this$wakeLock","_this$options$onAudio","_this$options","_this$outputFrequency","changeInputDevice","newInput","changeOutputDevice","newOutput","postOverallFeedback","likeOrFeedback","feedback","rating","comment","method","headers","EventEmitter","listeners","listener","has","Set","eventListeners","add","delete","emit","args","RealtimeEvents","RealtimeConnection","websocket","eventEmitter","currentSampleRate","_audioCleanup","setWebSocket","readyState","OPEN","message_type","SESSION_STARTED","PARTIAL_TRANSCRIPT","COMMITTED_TRANSCRIPT","COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS","AUTH_ERROR","QUOTA_EXCEEDED","ERROR","log","wasClean","errorMessage","CLOSE","_data$commit","_data$sampleRate","audioBase64","commit","sample_rate","loadScribeAudioProcessor","AudioFormat","CommitStrategy","ScribeRealtime","getWebSocketUri","baseUri","DEFAULT_BASE_URI","buildWebSocketUri","params","URLSearchParams","append","modelId","undefined","commitStrategy","vadSilenceThresholdSecs","vadThreshold","minSpeechDurationMs","minSilenceDurationMs","languageCode","includeTimestamps","queryString","microphone","uri","streamFromMicrophone","_options$microphone","_options$microphone$e","_options$microphone2","_options$microphone$n","_options$microphone3","_options$microphone$a","_options$microphone4","_options$microphone$c","_options$microphone5","workletNode","binary","Conversation"],"mappings":"wUA8DA,MAAMA,EAAuB,IAAIC,WAAW,SAE/BC,EASD,qBAAOC,CAAeC,GAC9B,OAAAC,EAAA,CACEC,YAAa,CAAE,EACfC,UAAWA,OACXC,QAASA,OACTC,aAAcA,OACdC,QAASA,OACTC,UAAWA,OACXC,QAASA,OACTC,aAAcA,OACdC,eAAgBA,OAChBC,wBAAyBA,OACzBC,eAAgBA,QACbZ,EAEP,CAEAa,WAAAA,CACqBC,EACAC,GAA0B,IAAAC,EAD1BF,KAAAA,KAAAA,oBACAC,gBAAA,EAAAE,KA3BXC,uBAAyB,EAACD,KAC1BE,KAAa,YACbC,KAAAA,OAAiB,kBACjBC,OAAS,EAACJ,KACVK,eAAiB,EACjBC,KAAAA,oBAAsB,EAACN,KACvBO,iBAAkB,EAoCpBC,KAAAA,sBAAwBC,eAAOC,GACjB,cAAhBX,EAAKI,QAA0C,eAAhBJ,EAAKI,SACxCJ,EAAKY,aAAa,uBACZZ,EAAKa,mBACXb,EAAKY,aAAa,gBACdZ,EAAKF,QAAQT,cACfW,EAAKF,QAAQT,aAAasB,GAE9B,EAACV,KAqNOV,UAAYmB,eAAOI,GACzB,OAAQA,EAAYC,MAClB,IAAK,eAEH,YADAf,EAAKgB,mBAAmBF,GAG1B,IAAK,iBAEH,YADAd,EAAKiB,oBAAoBH,GAG3B,IAAK,kBAEH,YADAd,EAAKkB,qBAAqBJ,GAG5B,IAAK,oCAEH,YADAd,EAAKmB,6BAA6BL,GAGpC,IAAK,mBACH,UACQd,EAAKoB,qBAAqBN,EAClC,CAAE,MAAOO,GACPrB,EAAKV,QACH,kDAAkD+B,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,KAClG,CACEI,eAAgBX,EAAYY,iBAAiBC,UAC7CC,WAAYd,EAAYY,iBAAiBG,cAG/C,CACA,OAEF,IAAK,QAEH,YADA7B,EAAK8B,YAAYhB,GAInB,IAAK,YAEH,YADAd,EAAK+B,eAAejB,GAItB,IAAK,OAOH,YANAd,EAAKD,WAAWiC,YAAY,CAC1BjB,KAAM,OACNkB,SAAUnB,EAAYoB,WAAWD,WAOrC,IAAK,gBAEH,YADAjC,EAAKmC,kBAAkBrB,GAIzB,IAAK,wBAEH,YADAd,EAAKoC,0BAA0BtB,GAIjC,IAAK,sBAEH,YADAd,EAAKqC,wBAAwBvB,GAI/B,IAAK,mCAEH,YADAd,EAAKsC,2BAA2BxB,GAIlC,IAAK,0BAEH,YADAd,EAAKuC,4BAA4BzB,GAInC,IAAK,2BAEH,YADAd,EAAKwC,4BAA4B1B,GAInC,IAAK,QAEH,YADAd,EAAKyC,iBAAiB3B,GAIxB,QAIE,YAHId,EAAKF,QAAQV,SACfY,EAAKF,QAAQV,QAAQ0B,IAK7B,OAiBO4B,UAAY,EAAGrC,aACpBJ,KAAKI,OAASA,GA7VKJ,KAAOH,QAAPA,EACAG,KAAUF,WAAVA,EAEfE,KAAKH,QAAQX,WACfc,KAAKH,QAAQX,UAAU,CAAEwD,eAAgB5C,EAAW4C,iBAEtD1C,KAAKF,WAAWR,UAAUU,KAAKV,WAC/BU,KAAKF,WAAWV,aAAaY,KAAKQ,uBAClCR,KAAKF,WAAWN,aAAaU,GAAQF,KAAK2C,WAAWzC,IACrDF,KAAKW,aAAa,YACpB,CAEOiC,UAAAA,GACL,OAAO5C,KAAKQ,sBAAsB,CAAEqC,OAAQ,QAC9C,CAYU,sBAAMjC,GACdZ,KAAKF,WAAWgD,OAClB,CAEUH,UAAAA,CAAWzC,GACfA,IAASF,KAAKE,OAChBF,KAAKE,KAAOA,EACRF,KAAKH,QAAQL,cACfQ,KAAKH,QAAQL,aAAa,CAAEU,SAGlC,CAEUS,YAAAA,CAAaR,GACjBA,IAAWH,KAAKG,SAClBH,KAAKG,OAASA,EACVH,KAAKH,QAAQJ,gBACfO,KAAKH,QAAQJ,eAAe,CAAEU,WAGpC,CAEU4C,qBAAAA,GACR,MAAMxC,EAAkBP,KAAKK,iBAAmBL,KAAKM,oBACjDN,KAAKO,kBAAoBA,IAC3BP,KAAKO,gBAAkBA,EACnBP,KAAKH,QAAQH,yBACfM,KAAKH,QAAQH,wBAAwB,CAAEa,oBAG7C,CAEUQ,kBAAAA,CAAmBiC,GACvBA,EAAMC,qBACRjD,KAAKC,uBAAyB+C,EAAMC,mBAAmBjB,SAEnDhC,KAAKH,QAAQF,gBACfK,KAAKH,QAAQF,eAAe,CAC1BqC,SAAUgB,EAAMC,mBAAmBjB,WAI3C,CAEUhB,mBAAAA,CAAoBgC,GACxBhD,KAAKH,QAAQP,WACfU,KAAKH,QAAQP,UAAU,CACrB4D,OAAQ,KACR5B,QAAS0B,EAAMG,qBAAqBC,gBAG1C,CAEUnC,oBAAAA,CAAqB+B,GACzBhD,KAAKH,QAAQP,WACfU,KAAKH,QAAQP,UAAU,CACrB4D,OAAQ,OACR5B,QAAS0B,EAAMK,yBAAyBC,iBAG9C,CAEUpC,4BAAAA,CACR8B,GAEIhD,KAAKH,QAAQV,SACfa,KAAKH,QAAQV,QAAQ,CACnB2B,KAAM,2BACNyC,SACEP,EAAMQ,wCACHC,0BAGX,CAEU3B,cAAAA,CAAekB,GACnBhD,KAAKH,QAAQ6D,YACf1D,KAAKH,QAAQ6D,WAAW,CACtBC,SAAUX,EAAMY,gBAAgBC,WAGtC,CAEU,0BAAM1C,CAAqB6B,GACnC,GACEc,OAAOC,UAAUC,eAAeC,KAC9BjE,KAAKH,QAAQZ,YACb+D,EAAMvB,iBAAiBC,WAGzB,IAAI,IAAAwC,EACF,MAAMC,EAGHD,OAHSA,QACHlE,KAAKH,QAAQZ,YAAY+D,EAAMvB,iBAAiBC,WACrDsB,EAAMvB,iBAAiB2C,aACxBF,EAAK,oCAGFG,EACc,iBAAXF,EAAsBG,KAAKC,UAAUJ,GAAU5C,OAAO4C,GAE/DnE,KAAKF,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcoB,EAAMvB,iBAAiBG,aACrCuC,OAAQE,EACRG,UAAU,GAEd,CAAE,MAAOC,GACPzE,KAAKX,QACH,sDAAuDoF,MAAAA,OAAAA,EAAAA,EAAanD,UACpE,CACEE,eAAgBwB,EAAMvB,iBAAiBC,YAG3C1B,KAAKF,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcoB,EAAMvB,iBAAiBG,aACrCuC,OAAQ,iCAA6C,MAAXM,OAAW,EAAXA,EAAanD,UACvDkD,UAAU,GAEd,KACK,CACL,GAAIxE,KAAKH,QAAQ6E,0BAGf,YAFA1E,KAAKH,QAAQ6E,0BAA0B1B,EAAMvB,kBAK/CzB,KAAKX,QACH,yBAAyB2D,EAAMvB,iBAAiBC,qCAChD,CACEF,eAAgBwB,EAAMvB,iBAAiBC,YAG3C1B,KAAKF,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcoB,EAAMvB,iBAAiBG,aACrCuC,OAAQ,yBAAyBnB,EAAMvB,iBAAiBC,qCACxD8C,UAAU,GAEd,CACF,CAEU3C,WAAAA,CAAYmB,GAAsB,CAElCd,iBAAAA,CAAkBc,GACtBhD,KAAKH,QAAQ8E,eACf3E,KAAKH,QAAQ8E,cAAc3B,EAAM4B,cAErC,CAEUzC,yBAAAA,CAA0Ba,GAC9BhD,KAAKH,QAAQgF,uBACf7E,KAAKH,QAAQgF,sBAAsB7B,EAAM8B,sBAE7C,CAEU1C,uBAAAA,CAAwBY,GACY,aAAxCA,EAAM+B,oBAAoBrD,WAC5B1B,KAAKQ,sBAAsB,CACzBqC,OAAQ,QACRmC,QAAS,IAAIC,WAAW,WAAY,CAAEpC,OAAQ,2BAI9C7C,KAAKH,QAAQqF,qBACflF,KAAKH,QAAQqF,oBAAoBlC,EAAM+B,oBAE3C,CAEU1C,0BAAAA,CAA2BW,GAC/BhD,KAAKH,QAAQsF,wBACfnF,KAAKH,QAAQsF,uBACXnC,EAAMoC,uCAGZ,CAEU9C,2BAAAA,CAA4BU,GAChChD,KAAKH,QAAQwF,yBACfrF,KAAKH,QAAQwF,wBAAwBrC,EAAMsC,8BAE/C,CAEU/C,2BAAAA,CAA4BS,GAChChD,KAAKH,QAAQ0F,yBACfvF,KAAKH,QAAQ0F,wBAAwBvC,EAAMwC,mBAE/C,CAEUhD,gBAAAA,CAAiBQ,GACzB,MAAMyC,EAAYzC,EAAM0C,YAAYC,WAC9BrE,EACJ0B,EAAM0C,YAAYpE,SAAW0B,EAAM0C,YAAY7C,QAAU,gBAEzC,0BAAd4C,EASJzF,KAAKX,QAAQ,iBAAiBiC,IAAW,CACvCmE,YACAG,KAAM5C,EAAM0C,YAAYE,KACxBC,aAAc7C,EAAM0C,YAAYI,cAChCpF,QAASsC,EAAM0C,YAAYhF,UAZ3BV,KAAKQ,sBAAsB,CACzBqC,OAAQ,QACRvB,QAASA,EACT0D,QAAS,IAAIe,MAAM,0BAWzB,CAkGQ1G,OAAAA,CAAQiC,EAAiB0D,GAC/BgB,QAAQ5E,MAAME,EAAS0D,GACnBhF,KAAKH,QAAQR,SACfW,KAAKH,QAAQR,QAAQiC,EAAS0D,EAElC,CAEOiB,KAAAA,GACL,OAAOjG,KAAKF,WAAW4C,cACzB,CAEOwD,MAAAA,GACL,MAAuB,mBAAX/F,MACd,CAMOgG,WAAAA,CAAYC,GACjBpG,KAAKF,WAAWqG,YAAYC,EAC9B,CAEOC,yBAAAA,GACL,OAAO1H,CACT,CAEO2H,0BAAAA,GACL,OAAO3H,CACT,CAEO4H,cAAAA,GACL,QACF,CAEOC,eAAAA,GACL,OACF,CAAA,CAEOC,YAAAA,CAAaC,GACb1G,KAAKO,iBASVP,KAAKF,WAAWiC,YAAY,CAC1BjB,KAAM,WACN6F,MAAOD,EAAO,OAAS,UACvB1E,SAAUhC,KAAKK,iBAEjBL,KAAKM,oBAAsBN,KAAKK,eAChCL,KAAK+C,yBAdHiD,QAAQY,KACuB,IAA7B5G,KAAKM,oBACD,8DACA,iFAYV,CAEOuG,oBAAAA,CAAqBC,GAC1B9G,KAAKF,WAAWiC,YAAY,CAC1BjB,KAAM,oBACNgG,QAEJ,CAEOC,eAAAA,CAAgBD,GACrB9G,KAAKF,WAAWiC,YAAY,CAC1BjB,KAAM,eACNgG,QAEJ,CAEOE,gBAAAA,GACLhH,KAAKF,WAAWiC,YAAY,CAC1BjB,KAAM,iBAEV,CAEOmG,yBAAAA,CAA0BtF,EAAoBuF,GACnDlH,KAAKF,WAAWiC,YAAY,CAC1BjB,KAAM,2BACNc,aAAcD,EACdwF,YAAaD,GAEjB,QCvaoBE,EAYpBxH,WAAAA,CAAYyH,EAAgD,CAAE,GAPpDC,KAAAA,MAA+B,QAC/BC,qBAAoD,KAAIvH,KACxDwH,qBAAoD,KACpDC,KAAAA,kBAA8C,KAAIzH,KAClD0H,qBAAsD,KACtDvI,KAAAA,aAGR,EAAAa,KAAKb,QAAUkI,EAAOlI,OACxB,CAEUwI,KAAAA,CAAMC,GACV5H,KAAKb,SAASa,KAAKb,QAAQyI,EACjC,CAMOtI,SAAAA,CAAUuI,GACf7H,KAAKyH,kBAAoBI,EACzB,MAAMP,EAAQtH,KAAKsH,MACnBtH,KAAKsH,MAAQ,GAETA,EAAMQ,OAAS,GAGjBC,eAAe,KACbT,EAAMU,QAAQH,IAGpB,CAEOzI,YAAAA,CAAayI,GAClB7H,KAAKwH,qBAAuBK,EAC5B,MAAMnH,EAAUV,KAAKuH,qBACjB7G,GAGFqH,eAAe,KACbF,EAASnH,IAGf,CAEOlB,YAAAA,CAAaqI,GAClB7H,KAAK0H,qBAAuBG,CAC9B,CAEUlF,UAAAA,CAAWzC,GAAU+H,IAAAA,EAC7BA,OAAAA,EAAIjI,KAAC0H,uBAALO,EAAAhE,UAA4B/D,EAC9B,CAEUgI,UAAAA,CAAWxH,GACayH,IAAAA,EAA3BnI,KAAKuH,uBACRvH,KAAKuH,qBAAuB7G,SAC5ByH,EAAAnI,KAAKwH,uBAALW,EAAAlE,KAAAjE,KAA4BU,GAEhC,CAEU0H,aAAAA,CAAcvH,GAClBb,KAAKyH,kBACPzH,KAAKyH,kBAAkB5G,GAEvBb,KAAKsH,MAAMe,KAAKxH,EAEpB,EAGc,SAAAyH,EAAYC,GAC1B,MAAOC,EAAYC,GAAkBF,EAAOG,MAAM,KAClD,IAAK,CAAC,MAAO,QAAQC,SAASH,GAC5B,MAAM,IAAInH,MAAM,mBAAmBkH,KAGrC,MAAMK,EAAaC,OAAOC,SAASL,GACnC,GAAII,OAAOE,MAAMH,GACf,MAAU,IAAAvH,MAAM,wBAAwBoH,KAG1C,MAAO,CACLF,OAAQC,EACRI,aAEJ,CC7Ka,MAAAI,EAAkB,SCoFf,SAAAC,EAAmBjG,GACjC,QAASA,EAAMlC,IACjB,CCpFO,MAAMoI,EACX,sCAEc,SAAAC,EACd9B,GAAqB,IAAA+B,EAErB,MAAMC,EAA4C,CAChDvI,KAAMoI,OAGcI,EAAAC,EAAAC,EAAAC,EAAAC,EAmCtB,OAnCIrC,EAAOsC,YACTN,EAAeO,6BAA+B,CAC5CC,MAAO,CACLC,OAAQR,OAAFA,EAAEjC,EAAOsC,UAAUE,YAAjBP,EAAAA,EAAwBQ,OAChCC,cAAeR,OAAFA,EAAElC,EAAOsC,UAAUE,YAAjBN,EAAAA,EAAwBS,aACvCC,SAAgC,OAAxBT,EAAEnC,EAAOsC,UAAUE,YAAK,EAAtBL,EAAwBS,UAEpCC,IAAK,CACHC,SAA8B,OAAtBV,EAAEpC,EAAOsC,UAAUO,UAAG,EAApBT,EAAsBW,SAElCC,aAAc,CACZC,UAAwC,OAA/BZ,EAAErC,EAAOsC,UAAUU,mBAAY,EAA7BX,EAA+Ba,YAK5ClD,EAAOmD,qBACTnB,EAAeoB,sBAAwBpD,EAAOmD,oBAG5CnD,EAAOqD,mBACTrB,EAAesB,kBAAoBtD,EAAOqD,kBAGxCrD,EAAOuD,SACTvB,EAAewB,QAAUxD,EAAOuD,QAG9BxB,OAAJA,EAAI/B,EAAOsC,YAAPP,EAAkB0B,SACpBzB,EAAe0B,YAAc,CAC3B7H,OAAQmE,EAAOsC,UAAUmB,OAAO5H,OAChC8H,QAAS3D,EAAOsC,UAAUmB,OAAOE,UAI9B3B,CACT,CC/BM,MAAO4B,UAA4B7D,EAKvCxH,WAAAA,CACmBsL,EACjBxI,EACAyI,EACAC,GAEAC,QAAQrL,KALSkL,mBALHxI,oBAAc,EAAA1C,KACdmL,iBACAC,EAAAA,KAAAA,oBAGGpL,KAAMkL,OAANA,EAMjBlL,KAAK0C,eAAiBA,EACtB1C,KAAKmL,YAAcA,EACnBnL,KAAKoL,aAAeA,EAEpBpL,KAAKkL,OAAOI,iBAAiB,QAAStI,IAIpCuI,WACE,IACEvL,KAAKkI,WAAW,CACdrF,OAAQ,QACRvB,QAAS,mDACT0D,QAAShC,IAEb,KAIJhD,KAAKkL,OAAOI,iBAAiB,QAAStI,IACpChD,KAAKkI,WACY,MAAflF,EAAM4C,KACF,CACE/C,OAAQ,QACRmC,QAAShC,GAEX,CACEH,OAAQ,QACRvB,QACE0B,EAAMH,QAAU,2CAClBmC,QAAShC,MAKnBhD,KAAKkL,OAAOI,iBAAiB,UAAWtI,IACtC,IACE,MAAMnC,EAAcyD,KAAKkH,MAAMxI,EAAMyI,MACrC,IAAKxC,EAAmBpI,GAMtB,YALAb,KAAK2H,MAAM,CACT7G,KAAM,gBACNQ,QAAS,gCACTmK,KAAMzI,EAAMyI,OAIhBzL,KAAKoI,cAAcvH,EACrB,CAAE,MAAOO,GACPpB,KAAK2H,MAAM,CACT7G,KAAM,gBACNQ,QAAS,iCACTF,MAAOA,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,GACvDqK,KAAMzI,EAAMyI,MAEhB,GAEJ,CAEO,mBAAaC,CAClBrE,GAEA,IAAI6D,EAA2B,KAE/B,IAAI,IAAAS,EAAAvC,EAAAwC,EACF,MAAMC,EAAsBF,OAAhBA,EAAGtE,EAAOwE,QAAMF,EA/EX,0BAgFjB,IAAIG,EAEJ,MAAMd,GAA0B,OAAhB5B,EAAA/B,EAAOsC,YAAiB,OAARP,EAAhBA,EAAkB0B,aAAM,EAAxB1B,EAA0B4B,UAAWhC,EAC/C9F,GAAyB0I,OAAhBA,EAAAvE,EAAOsC,YAAiB,OAARiC,EAAhBA,EAAkBd,aAAM,EAAxBc,EAA0B1I,SAAU,SAEnD,GAAImE,EAAO0E,UAAW,CACpB,MAAMC,EAAY3E,EAAO0E,UAAUpD,SAAS,KAAO,IAAM,IACzDmD,EAAM,GAAGzE,EAAO0E,YAAYC,WAAmB9I,aAAkB8H,GACnE,MACEc,EAAM,GAAGD,qCAA4BxE,EAAO4E,kBAAkB/I,aAAkB8H,IAGlF,MAAMkB,EAAY,CA7FF,UA8FZ7E,EAAO8E,eACTD,EAAU7D,KAAK,UAAUhB,EAAO8E,iBAElCjB,EAAS,IAAIkB,UAAUN,EAAKI,GAE5B,MAAMG,YAA+BC,QAEnC,CAACC,EAASC,KACVtB,EAAQI,iBACN,OACA,SAAKmB,EACH,MAAMpD,EAAiBF,EAAmB9B,GAE1CoF,OAAAA,EAAAvB,IAAAuB,EAAQC,KAAKpI,KAAKC,UAAU8E,KAE9B,CAAEsD,MAAM,IAGVzB,EAAQI,iBAAiB,QAAStI,IAIhCuI,WAAW,IAAMiB,EAAOxJ,GAAQ,KAGlCkI,EAAQI,iBAAiB,QAASkB,GAElCtB,EAAQI,iBACN,UACCtI,IACC,MAAM1B,EAAUgD,KAAKkH,MAAMxI,EAAMyI,MAE5BxC,EAAmB3H,KAIH,qCAAjBA,EAAQR,KACVyL,EAAQjL,EAAQ8D,wCAEhBY,QAAQY,KACN,0DAIN,CAAE+F,MAAM,OAINC,gBACJA,EAAeC,0BACfA,EAAyBC,wBACzBA,GACET,EAEElB,EAAc7C,EAAYwE,MAAAA,EAAAA,EAA2B,aACrD1B,EAAe9C,EAAYuE,GAEjC,WAAW5B,EACTC,EACA0B,EACAzB,EACAC,EAEJ,CAAE,MAAOhK,GAAO2L,IAAAA,EAEd,MADM,OAANA,EAAA7B,IAAA6B,EAAQjK,QACF1B,CACR,CACF,CAEO0B,KAAAA,GACL9C,KAAKkL,OAAOpI,OACd,CAEOf,WAAAA,CAAYT,GACjBtB,KAAKkL,OAAOwB,KAAKpI,KAAKC,UAAUjD,GAClC,CAEO,iBAAM6E,CAAYC,GACvBJ,QAAQY,KACN,gDAAgDR,8CAEpD,EC7LI,SAAU4G,EAAoBC,GAClC,MAAMC,EAAS,IAAItO,WAAWqO,GAG9B,OADmBE,OAAOC,KAAK7L,OAAO8L,gBAAgBH,GAExD,UAEgBI,EAAoBC,GAClC,MAAMC,EAAeL,OAAOM,KAAKF,GAC3BG,EAAMF,EAAa1F,OACnB6F,EAAQ,IAAI/O,WAAW8O,GAC7B,IAAK,IAAIE,EAAI,EAAGA,EAAIF,EAAKE,IACvBD,EAAMC,GAAKJ,EAAaK,WAAWD,GAErC,OAAOD,EAAMT,MACf,CCfA,MAAMY,EAAW,IAAIC,IAEL,SAAAC,EAA0BC,EAAcC,GACtD,OAAcC,MAAAA,EAAuBC,KACnC,MAAMC,EAAYP,EAASQ,IAAIL,GAC/B,GAAII,EACF,OAAOF,EAAQI,UAAUF,GAI3B,GAAID,EACF,IAGE,aAFMD,EAAQI,UAAUH,QACxBN,EAASU,IAAIP,EAAMG,EAErB,CAAE,MAAOhN,GACP,UAAUC,MACR,sBAAsB4M,+BAAkCG,aAAgBhN,IAE5E,CAGF,MAAMqN,EAAO,IAAIC,KAAK,CAACR,GAAa,CAAEpN,KAAM,2BACtC6N,EAAUC,IAAIC,gBAAgBJ,GACpC,IAGE,aAFMN,EAAQI,UAAUI,QACxBb,EAASU,IAAIP,EAAMU,EAErB,CAAE,MAAAG,GACAF,IAAIG,gBAAgBJ,EACtB,CAEA,IAIE,MACMK,EAAY,sCADH5B,KAAKc,WAEdC,EAAQI,UAAUS,GACxBlB,EAASU,IAAIP,EAAMe,EACrB,CAAE,MAAO5N,GACP,MAAU,IAAAC,MACR,sBAAsB4M,8IAE1B,EAEJ,CC3CO,MAAMgB,EAAwBjB,EACnC,oBAEA,g2HCiCI,MAAOkB,UAAyB9H,EAepCxH,WAAAA,CACEuP,EACAzM,EACAyI,EACAC,EACA/D,EAAgD,CAAE,GAElDgE,MAAMhE,GAAQrH,KArBT0C,oBACSyI,EAAAA,KAAAA,iBACAC,EAAAA,KAAAA,yBAER+D,UAAI,EAAAnP,KACJoP,aAAc,EAAKpP,KACnBqP,aAAe,EAACrP,KAChBsP,oBAA2C,KAAItP,KAC/CuP,cAAoC,GACpCC,KAAAA,eAAgC,KAEhCC,KAAAA,eAAsC,KACtCC,KAAAA,oBAAsD,KAU5D1P,KAAKmP,KAAOA,EACZnP,KAAK0C,eAAiBA,EACtB1C,KAAKmL,YAAcA,EACnBnL,KAAKoL,aAAeA,EAEpBpL,KAAK2P,yBACP,CAEO,mBAAajE,CAClBrE,GAEA,IAAIuI,EAGJ,GAAI,sBAAuBvI,GAAUA,EAAOuI,kBAE1CA,EAAoBvI,EAAOuI,sBAClB,MAAA,YAAavI,KAAUA,EAAO4E,QAkCvC,MAAM,IAAI5K,MACR,yEAjCF,IAAI+H,IAAAA,EAAAwC,EAAAD,EACF,MAAMX,GAA0B5B,OAAhBA,EAAA/B,EAAOsC,YAAPP,OAAgBA,EAAhBA,EAAkB0B,aAAlB1B,EAAAA,EAA0B4B,UAAWhC,EAC/C9F,GAAyB0I,OAAhBA,EAAAvE,EAAOsC,YAAPiC,OAAgBA,EAAhBA,EAAkBd,aAAlBc,EAAAA,EAA0B1I,SAAU,SAG7C4I,EAAM,GAvDOD,EAqDe,OAAhBF,EAAGtE,EAAOwE,QAAMF,EAxDjB,4BAIhBE,EAAOgE,QAAQ,YAAa,qDAsDkCxI,EAAO4E,kBAAkB/I,aAAkB8H,IACpGzH,QAAiBuM,MAAMhE,GAE7B,IAAKvI,EAASwM,GACZ,MAAM,IAAI1O,MACR,2BAA2BkC,EAASpD,UAAUoD,EAASyM,cAO3D,GAFAJ,SADmBrM,EAAS0M,QACHC,OAEpBN,EACH,MAAU,IAAAvO,MAAM,0CAEpB,CAAE,MAAOD,GACP,IAAI+O,EAAM/O,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,GAM1D,MALIA,aAAiBC,OAASD,EAAME,QAAQqH,SAAS,SACnDwH,EACE,gGAGE,IAAI9O,MACR,gDAAgDgG,EAAO4E,YAAYkE,IAEvE,CAKF,CArFJ,IAA2BtE,EAuFvB,MAAMsD,EAAO,IAAIiB,EAEjB,IAEE,MAAM1N,EAAiB,QAAQ2N,KAAKC,QAC9BnF,EAAc7C,EAAY,aAC1B8C,EAAe9C,EAAY,aAC3BxI,EAAa,IAAIoP,EACrBC,EACAzM,EACAyI,EACAC,EACA/D,GAIIkJ,EAAalJ,EAAOkJ,YA3GD,kCA6HV,IAAAC,QAfTrB,EAAKsB,QAAQF,EAAYX,SAGrB,IAAAtD,QAAcC,IACtB,GAAIzM,EAAWsP,YACb7C,QACK,CACL,MAAMmE,EAAcA,KAClBvB,EAAKwB,IAAIC,EAAUC,UAAWH,GAC9BnE,KAEF4C,EAAK2B,GAAGF,EAAUC,UAAWH,EAC/B,IAGEvB,EAAKlB,OACPnO,EAAW4C,gBACT8N,OAAAA,EAAArB,EAAKlB,KAAK8C,MAAM,6BAAhBP,EAAAA,EAAyC,KAAMrB,EAAKlB,YAIlDkB,EAAK6B,iBAAiBC,sBAAqB,GAEjD,MAAM5H,EAAiBF,EAAmB9B,GAS1C,OAPAvH,EAAW6H,MAAM,CACf7G,KAAMoI,EACN5H,QAAS+H,UAGLvJ,EAAWiC,YAAYsH,GAEtBvJ,CACT,CAAE,MAAOsB,GAEP,YADM+N,EAAKjH,aACL9G,CACR,CACF,CAEQuO,uBAAAA,GAAuB,IAAA5P,EAAAC,KAC7BA,KAAKmP,KAAK2B,GAAGF,EAAUC,UAAWpQ,iBAChCV,EAAKqP,aAAc,EACnBpJ,QAAQ4B,KAAK,wBACf,GAEA5H,KAAKmP,KAAK2B,GAAGF,EAAUM,aAAcrO,IACnC7C,KAAKoP,aAAc,EACnBpP,KAAKkI,WAAW,CACdrF,OAAQ,QACRmC,QAAS,IAAIC,WAAW,QAAS,CAAEpC,OAAc,MAANA,OAAM,EAANA,EAAQsO,iBAIvDnR,KAAKmP,KAAK2B,GAAGF,EAAUQ,uBAAwBC,IACzCA,IAAUC,EAAgBJ,eAC5BlR,KAAKoP,aAAc,EACnBpP,KAAKkI,WAAW,CACdrF,OAAQ,QACRvB,QAAS,uCAAuC+P,IAChDrM,QAAS,IAAIe,MAAM,iCAMzB/F,KAAKmP,KAAK2B,GACRF,EAAUW,aACV,CAACC,EAAqBC,KACpB,IACE,MAAMnQ,EAAUgD,KAAKkH,OAAM,IAAIkG,aAAcC,OAAOH,IAGpD,GAAqB,UAAjBlQ,EAAQR,KACV,OAGEmI,EAAmB3H,GACrBtB,KAAKoI,cAAc9G,GAEnB0E,QAAQY,KAAK,iCAAkCtF,EAEnD,CAAE,MAAOF,GACP4E,QAAQY,KAAK,yCAA0CxF,GACvD4E,QAAQY,KAAK,gBAAgB,IAAI8K,aAAcC,OAAOH,GACxD,IAIJxR,KAAKmP,KAAK2B,GACRF,EAAUgB,gBACVnR,eACEoR,EACAC,EACAC,GAEA,GACEF,EAAMG,OAASC,EAAMC,KAAKC,OAC1BJ,EAAYK,SAASzJ,SAAS,SAC9B,CAEA,MAAM0J,EAAmBR,EACnBS,EAAeD,EAAiBE,SAKtC,GAJAD,EAAaE,UAAW,EACxBF,EAAaG,UAAW,EAGpB1S,EAAKyP,gBAAkB8C,EAAaI,UACtC,UACQJ,EAAaI,UAAU3S,EAAKyP,eACpC,CAAE,MAAOpO,GACP4E,QAAQY,KACN,qDACAxF,EAEJ,CAIFkR,EAAaK,MAAMC,QAAU,OAC7BC,SAASC,KAAKC,YAAYT,GAG1BvS,EAAKwP,cAAclH,KAAKiK,GAGU,IAA9BvS,EAAKwP,cAAczH,SAErB/H,MAAAA,EAAKZ,SAALY,EAAKZ,QAAU,CAAE2B,KAAM,+BAInBf,EAAKiT,kBAAkBX,EAC/B,CACF,GAGFrS,KAAKmP,KAAK2B,GACRF,EAAUqC,sBACVxS,eAAOyS,GAEHnT,EAAK4C,WADHuQ,EAASpL,OAAS,GAElBoL,EAAS,GAAGd,SAASe,WAAW,SAAW,WAG7B,YAEpB,EAEJ,CAEOrQ,KAAAA,GACL,GAAI9C,KAAKoP,YAAa,CACpB,IAEEpP,KAAKmP,KAAK6B,iBAAiBoC,uBAAuBpL,QAChDqL,IACMA,EAAYxB,OACdwB,EAAYxB,MAAMyB,QAI1B,CAAE,MAAOlS,GACP4E,QAAQY,KAAK,+BAAgCxF,EAC/C,CAGIpB,KAAKsP,sBACPtP,KAAKsP,oBAAoBxM,QAAQyQ,MAAMnS,IACrC4E,QAAQY,KAAK,uCAAwCxF,KAEvDpB,KAAKsP,oBAAsB,MAI7BtP,KAAKuP,cAAcvH,QAAQwL,IACrBA,EAAQC,YACVD,EAAQC,WAAWC,YAAYF,KAGnCxT,KAAKuP,cAAgB,GAErBvP,KAAKmP,KAAKjH,YACZ,CACF,CAEO,iBAAMnG,CAAYT,GACvB,GAAKtB,KAAKoP,aAAgBpP,KAAKmP,KAAK6B,kBAQpC,KAAI,qBAAsB1P,GAK1B,IACE,MACMmK,GADU,IAAIkI,aACCC,OAAOtP,KAAKC,UAAUjD,UAEjCtB,KAACmP,KAAK6B,iBAAiB6C,YAAYpI,EAAM,CAAEqI,UAAU,GACjE,CAAE,MAAO1S,GACPpB,KAAK2H,MAAM,CACT7G,KAAM,qBACNQ,QAAS,CACPA,UACAF,WAGJ4E,QAAQ5E,MAAM,qCAAsCA,EACtD,OA1BE4E,QAAQY,KACN,kEA0BN,CAGOmN,OAAAA,GACL,OAAO/T,KAAKmP,IACd,CAEO,iBAAMhJ,CAAYC,GACvB,IAAKpG,KAAKoP,cAAgBpP,KAAKmP,KAAK6B,iBAIlC,YAHAhL,QAAQY,KACN,2EAMJ,MAAMoN,EAAsBhU,KAAKmP,KAAK6B,iBAAiBiD,oBACrDhC,EAAMiC,OAAOC,YAGf,GAAIH,MAAAA,GAAAA,EAAqBnC,MACvB,IAEMzL,QACI4N,EAAoBnC,MAAMuC,aAE1BJ,EAAoBnC,MAAMwC,QAEpC,CAAE,MAAOC,SAEGtU,KAACmP,KAAK6B,iBAAiBC,sBAAsB7K,EACzD,YAGUpG,KAACmP,KAAK6B,iBAAiBC,sBAAsB7K,EAE3D,CAEQ,uBAAM4M,CAAkBnB,GAC9B,IAEE,MAAM0C,EAAe,IAAIC,aACzBxU,KAAKsP,oBAAsBiF,EAG3BvU,KAAKyP,eAAiB8E,EAAaE,iBACnCzU,KAAKyP,eAAeiF,QAAU,KAC9B1U,KAAKyP,eAAekF,sBAAwB,GAG5C,MAAMC,EAAc,IAAIC,YAAY,CAAChD,EAAMiD,mBAGrC5R,EAASqR,EAAaQ,wBAAwBH,GAGpD1R,EAAOuN,QAAQzQ,KAAKyP,sBAEdR,EAAsBsF,EAAaS,cACzC,MAAM7G,EAAU,IAAI8G,iBAAiBV,EAAc,qBAGnDvU,KAAKyP,eAAegB,QAAQtC,GAG5BA,EAAQ+G,KAAKC,YAAY,CACvBrU,KAAM,YACNyH,OAAQvI,KAAKoL,aAAa7C,OAC1BK,WAAY5I,KAAKoL,aAAaxC,aAIhCuF,EAAQ+G,KAAKE,UAAapS,IACxB,MAAOqS,EAAWC,GAAatS,EAAMyI,KAKrC,GAAI6J,EAFoB,IAES,CAE/B,MAAMC,EAAcvI,EAAoBqI,EAAUnI,QAG5CsI,EAAUxV,KAAKqP,eAGrBrP,KAAKoI,cAAc,CACjBtH,KAAM,QACN2U,YAAa,CACXC,cAAeH,EACfvT,SAAUwT,IAGhB,GAIFtS,EAAOuN,QAAQtC,EACjB,CAAE,MAAO/M,GACP4E,QAAQY,KAAK,kCAAmCxF,EAClD,CACF,CAEOuU,cAAAA,CAAevV,GACpBJ,KAAKuP,cAAcvH,QAAQwL,IACzBA,EAAQpT,OAASA,GAErB,CAEO,0BAAMwV,CAAqBC,GAChC,KAAM,cAAeC,iBAAiB/R,WACpC,MAAM,IAAI1C,MAAM,8CAIlB,MAAM0U,EAAW/V,KAAKuP,cAAcyG,IAAIvV,eAAM+S,GAC5C,UACQA,EAAQd,UAAUmD,EAC1B,CAAE,MAAOzU,GAEP,MADA4E,QAAQ5E,MAAM,2CAA4CA,GACpDA,CACR,CACF,SAEMkL,QAAQ2J,IAAIF,GAGlB/V,KAAKwP,eAAiBqG,CACxB,CAEO,yBAAMK,CAAoBL,GAC/B,IAAK7V,KAAKoP,cAAgBpP,KAAKmP,KAAK6B,iBAClC,MAAU,IAAA3P,MACR,0EAIJ,IAEE,MAAM8U,EACJnW,KAAKmP,KAAK6B,iBAAiBiD,oBAAoBhC,EAAMiC,OAAOC,YAGhC,MAA1BgC,GAAAA,EAA4BtE,cACxBsE,EAA2BtE,MAAMyB,aAC7BtT,KAACmP,KAAK6B,iBAAiBoF,eAC/BD,EAA2BtE,QAK/B,MAAMwE,EAA0C,CAC9CR,SAAU,CAAES,MAAOT,GACnBU,kBAAkB,EAClBC,kBAAkB,EAClBC,iBAAiB,EACjBC,aAAc,CAAEC,MAAO,IAInBC,QAAmBC,EAAsBR,SAGrCrW,KAACmP,KAAK6B,iBAAiB8F,aAAaF,EAAY,CACxD3I,KAAM,aACN/K,OAAQ+O,EAAMiC,OAAOC,YAEzB,CAAE,MAAO/S,GACP4E,QAAQ5E,MAAM,iCAAkCA,GAGhD,UACYpB,KAACmP,KAAK6B,iBAAiBC,sBAAqB,EACxD,CAAE,MAAO8F,GACP/Q,QAAQ5E,MACN,0DACA2V,EAEJ,CAEA,MAAM3V,CACR,CACF,CAEOkF,0BAAAA,GACL,OAAKtG,KAAKyP,gBAEc,MAAxBzP,KAAK0P,sBAAL1P,KAAK0P,oBAAwB,IAAI9Q,WAC/BoB,KAAKyP,eAAeuH,oBAEtBhX,KAAKyP,eAAewH,qBAAqBjX,KAAK0P,qBACnC1P,KAAC0P,qBANqB,IAOnC,ECxgBKjP,eAAeyW,EACpB7P,GAEA,MAAM8P,EAlBR,SAAiC9P,GAE/B,OAAIA,EAAO8P,eACF9P,EAAO8P,eAIZ,sBAAuB9P,GAAUA,EAAOuI,kBACnC,SAIF,WACT,CAKyBwH,CAAwB/P,GAE/C,OAAQ8P,GACN,IAAK,YACH,OAAOlM,EAAoBS,OAAOrE,GACpC,IAAK,SACH,OAAO6H,EAAiBxD,OAAOrE,GACjC,QACE,UAAUhG,MAAM,4BAA4B8V,KAElD,UCpCgBE,IACd,MACE,CACE,iBACA,mBACA,iBACA,OACA,SACA,QACA1O,SAAS2O,UAAUC,WAEpBD,UAAUE,UAAU7O,SAAS,QAAU,eAAgBkK,QAE5D,gBCVsB4E,EACpBC,EAA2B,CACzBC,QAAS,EAETC,QAAS,MAGX,IAAIC,EAAQH,EAAYC,YACDG,EAAvB,GDKO,WAAWC,KAAKT,UAAUE,WCJ/BK,EAA2BC,OAAtBA,EAAGJ,EAAYE,SAAOE,EAAID,OACtBR,GAAAA,IAAe,KAAAW,EACxBH,EAAuBG,OAAlBA,EAAGN,EAAYO,KAAGD,EAAIH,CAC7B,CAEIA,EAAQ,SACA,IAAAvL,QAAQC,GAAWhB,WAAWgB,EAASsL,GAErD,OCfaK,UAAyBrZ,EAC7B,yBAAasZ,CAClBtY,GAEA,MAAMuY,EAAcvZ,EAAiBC,eAAee,GAEhDuY,EAAY3Y,gBACd2Y,EAAY3Y,eAAe,CAAEU,OAAQ,eAEnCiY,EAAY1Y,yBACd0Y,EAAY1Y,wBAAwB,CAAEa,iBAAiB,IAErD6X,EAAY5Y,cACd4Y,EAAY5Y,aAAa,CAAEU,KAAM,cAE/BkY,EAAY1Y,yBACd0Y,EAAY1Y,wBAAwB,CAAEa,iBAAiB,IAGzD,IAAIT,EAAoC,KACxC,IAGE,aAFM2X,EAAWW,EAAYC,iBAC7BvY,QAAmBoX,EAAiBrX,GACzB,IAAAqY,EAAiBE,EAAatY,EAC3C,CAAE,MAAOsB,GAAO,IAAAkX,EAKd,MAJIF,EAAY3Y,gBACd2Y,EAAY3Y,eAAe,CAAEU,OAAQ,iBAE7B,OAAVmY,EAAAxY,IAAAwY,EAAYxV,QACN1B,CACR,CACF,EC1BF,MAGMmX,EAAqB,CACzBhC,kBAAkB,EAClBC,kBAAkB,EAElBC,iBAAiB,EAEjBC,aAAc,CAAEC,MAAO,UAGZ6B,EACJ,mBAAa9M,EAAO9C,WACzBA,EAAUL,OACVA,EAAMkQ,8BACNA,EAA6BC,cAC7BA,EAAaC,aACbA,EAAYC,kBACZA,IAEA,IAAI5T,EAA+B,KAC/B6T,EAAkC,KAEtC,IACE,MAAMhZ,EAAOb,EAAA,CACX4J,WAAY,CAAE+N,MAAO/N,IAClB2P,GAGL,GAAIlB,KAAiBoB,EAA+B,CAClD,MAEMK,SADE3L,OAAOmK,UAAUyB,aAAaC,oBACDC,KACnCC,GAGa,eAAXA,EAAElH,MACF,CAAC,SAAU,YAAa,YAAYiH,KAAKE,GACvCD,EAAEE,MAAMC,cAAc1Q,SAASwQ,KAGjCL,IACFjZ,EAAQgW,SAAW,CAAEc,MAAOmC,EAAYjD,UAE5C,CAEI6C,IACF7Y,EAAQgW,SAAW,CAAES,MAAOoC,IAG9B,MAAMY,EACJhC,UAAUyB,aAAaQ,0BAA0B3Q,WAEnD5D,EAAU,IAAImI,OAAOqH,aACnB8E,EAA+B,CAAE1Q,cAAe,CAAA,GAElD,MAAM4Q,EAAWxU,EAAQyP,iBACzB,IAAK6E,EAA8B,CAEjC,MAAMG,EAAmBb,GA3D/B,0GA4DY5T,EAAQgQ,aAAazG,UAAUkL,EACvC,OACMxK,EACJjK,EAAQgQ,aACR2D,MAAAA,OAAAA,EAAAA,EAAkC,mBAGpC,MAAMe,EAAW1a,EAAA,CAAK2a,gBAAgB,GAAS9Z,GAC/CgZ,QAAoBvB,UAAUyB,aAAaa,aAAa,CACtDC,MAAOH,IAGT,MAAMxW,EAAS8B,EAAQ+P,wBAAwB8D,GACzC1K,EAAU,IAAI8G,iBAAiBjQ,EAAS,qBAQ9C,OAPAmJ,EAAQ+G,KAAKC,YAAY,CAAErU,KAAM,YAAayH,SAAQK,eAEtD1F,EAAOuN,QAAQ+I,GACfA,EAAS/I,QAAQtC,SAEXnJ,EAAQ8U,SAEH,IAAAtB,EAAMxT,EAASwU,EAAUrL,EAAS0K,EAAa3V,EAC5D,CAAE,MAAO9B,GAAO,IAAA2Y,EAAAC,EAKd,aAJAD,EAAAlB,IAAAkB,EAAaE,YAAYjS,QAAQ6J,IAC/BA,EAAMyB,SAED,OAAP0G,EAAAhV,IAAAgV,EAASlX,QACH1B,CACR,CACF,CAEAxB,WAAAA,CACkBoF,EACAwU,EACArL,EACT0K,EACCqB,QAJQlV,aAAA,EAAAhF,KACAwZ,cACArL,EAAAA,KAAAA,oBACT0K,iBAAA,EAAA7Y,KACCka,uBAAA,EAJQla,KAAOgF,QAAPA,EACAhF,KAAQwZ,SAARA,EACAxZ,KAAOmO,QAAPA,EACTnO,KAAW6Y,YAAXA,EACC7Y,KAAiBka,kBAAjBA,CACP,CAEI,WAAMpX,GACX9C,KAAK6Y,YAAYoB,YAAYjS,QAAQ6J,IACnCA,EAAMyB,SAERtT,KAAKka,kBAAkBhS,wBACZlD,QAAQlC,OACrB,CAEOqX,QAAAA,CAAS/T,GACdpG,KAAKmO,QAAQ+G,KAAKC,YAAY,CAAErU,KAAM,WAAYsF,WACpD,CAEO,oBAAMgU,CAAe1B,GAC1B,IAEE,MAAM7Y,EAAOb,EACRuZ,CAAAA,EAAAA,GAGDG,IACF7Y,EAAQgW,SAAW,CAAES,MAAOoC,IAI9B,MAAMgB,EAAW1a,EAAA,CAAK2a,gBAAgB,GAAS9Z,GAGzCwa,QAAuB/C,UAAUyB,aAAaa,aAAa,CAC/DC,MAAOH,IAIT1Z,KAAK6Y,YAAYoB,YAAYjS,QAAQ6J,IACnCA,EAAMyB,SAERtT,KAAKka,kBAAkBhS,aAGvBlI,KAAK6Y,YAAcwB,EACnBra,KAAKka,kBACHla,KAAKgF,QAAQ+P,wBAAwBsF,GAGvCra,KAAKka,kBAAkBzJ,QAAQzQ,KAAKwZ,SACtC,CAAE,MAAOpY,GAEP,MADA4E,QAAQ5E,MAAM,iCAAkCA,GAC1CA,CACR,CACF,EC3JK,MAAMkZ,EAA2BtM,EACtC,uBAEA,i8ECEW,MAAAuM,EACJ,mBAAa7O,EAAO9C,WACzBA,EAAUL,OACVA,EAAMiH,eACNA,EAAcmJ,aACdA,IAEA,IAAI3T,EAA+B,KAC/BsN,EAAwC,KAC5C,IACEtN,EAAU,IAAIwP,aAAa,CAAE5L,eAC7B,MAAM4Q,EAAWxU,EAAQyP,iBACnB+F,EAAOxV,EAAQyV,aAGrBnI,EAAe,IAAIH,MACnBG,EAAaoI,IAAM,GACnBpI,EAAaqI,OACbrI,EAAaE,UAAW,EACxBF,EAAaK,MAAMC,QAAU,OAE7BC,SAASC,KAAKC,YAAYT,GAG1B,MAAMsI,EAAc5V,EAAQ6V,+BAC5BvI,EAAawI,UAAYF,EAAYG,OAErCP,EAAK/J,QAAQ+I,GACbA,EAAS/I,QAAQmK,SAEXN,EACJtV,EAAQgQ,aACI,MAAZ2D,OAAY,EAAZA,EAAqC,sBAEvC,MAAMxK,EAAU,IAAI8G,iBAAiBjQ,EAAS,wBAmB9C,OAlBAmJ,EAAQ+G,KAAKC,YAAY,CAAErU,KAAM,YAAayH,WAC9C4F,EAAQsC,QAAQ+J,SAEVxV,EAAQ8U,SAGVtK,GAAkB8C,EAAaI,iBAC3BJ,EAAaI,UAAUlD,GAGb,IAAI+K,EACpBvV,EACAwU,EACAgB,EACArM,EACAmE,EAIJ,CAAE,MAAOlR,GAAO,IAAA4Z,EAAAC,EAUd,MARID,OAAJA,EAAI1I,IAAA0I,EAAcvH,YAChBnB,EAAamB,WAAWC,YAAYpB,GAE1B,OAAZ2I,EAAA3I,IAAA2I,EAAcC,QACVlW,GAA6B,WAAlBA,EAAQqM,aACfrM,EAAQlC,QAGV1B,CACR,CACF,CAEAxB,WAAAA,CACkBoF,EACAwU,EACAgB,EACArM,EACAmE,QAJAtN,aAAA,EAAAhF,KACAwZ,cAAA,EAAAxZ,KACAwa,UAAA,EAAAxa,KACAmO,aACAmE,EAAAA,KAAAA,kBAJA,EAAAtS,KAAOgF,QAAPA,EACAhF,KAAQwZ,SAARA,EACAxZ,KAAIwa,KAAJA,EACAxa,KAAOmO,QAAPA,EACAnO,KAAYsS,aAAZA,CACf,CAEI,qBAAM6I,CAAgBtF,GAC3B,KAAM,cAAeC,iBAAiB/R,WACpC,MAAU,IAAA1C,MAAM,oDAIZrB,KAAKsS,aAAaI,UAAUmD,GAAY,GAChD,CAEO,WAAM/S,GAEP9C,KAAKsS,aAAamB,YACpBzT,KAAKsS,aAAamB,WAAWC,YAAY1T,KAAKsS,cAEhDtS,KAAKsS,aAAa4I,cACRlb,KAACgF,QAAQlC,OACrB,QCrFWsY,UAA0Bvc,EAC9B,yBAAasZ,CAClBtY,OAAuBwb,EAEvB,MAAMjD,EAAcvZ,EAAiBC,eAAee,GAEhDuY,EAAY3Y,gBACd2Y,EAAY3Y,eAAe,CAAEU,OAAQ,eAEnCiY,EAAY1Y,yBACd0Y,EAAY1Y,wBAAwB,CAAEa,iBAAiB,IAGzD,IAAI+a,EAAsB,KACtBxb,EAAoC,KACpCyb,EAAwB,KACxBC,EAA6C,KAE7CC,EAAoC,KACxC,GAAuBJ,OAAvBA,EAAIxb,EAAQ6b,cAAWL,EACrB,IACEI,QAAiBnE,UAAUmE,SAASE,QAAQ,SAC9C,CAAE,MAAOC,GAAI,CAKf,IAAIC,IAAAA,EA6BF,OA1BAL,QAA+BlE,UAAUyB,aAAaa,aAAa,CACjEC,OAAO,UAGHpC,EAAWW,EAAYC,iBAC7BvY,QAAmBoX,EAAiBrX,IACnCyb,EAAOC,SAAgBjP,QAAQ2J,IAAI,CAClCuC,EAAM9M,OAAM1M,EACPc,CAAAA,EAAAA,EAAWqL,aACdsN,8BAA+B5Y,EAAQ4Y,8BACvCC,cAAe7Y,EAAQ6Y,cACvBC,aAAc9Y,EAAQ8Y,aACtBC,kBAAmB/Y,EAAQ+Y,qBAE7B2B,EAAO7O,OAAM1M,KACRc,EAAWsL,aACdoE,CAAAA,eAAgB3P,EAAQ2P,eACxBmJ,aAAc9Y,EAAQ8Y,yBAI1BkD,EAAAL,IAAAK,EAAwB5B,YAAYjS,QAAQ6J,IAC1CA,EAAMyB,SAERkI,EAAyB,KAElB,IAAIJ,EACThD,EACAtY,EACAwb,EACAC,EACAE,EAEJ,CAAE,MAAOra,GAAO0a,IAAAA,EAAAxD,EAAAyD,EAAAC,EACV5D,EAAY3Y,gBACd2Y,EAAY3Y,eAAe,CAAEU,OAAQ,iBAEjB,OAAtB2b,EAAAN,IAAAM,EAAwB7B,YAAYjS,QAAQ6J,IAC1CA,EAAMyB,gBAERgF,EAAAxY,IAAAwY,EAAYxV,cACNiZ,OAANA,EAAMT,QAAAS,EAAAA,EAAOjZ,eACPkZ,OAANA,EAAMT,QAAAS,EAAAA,EAAQlZ,SACd,IAAImZ,IAAAA,QACY,OAAdA,EAAMR,QAAQ,EAARQ,EAAUC,WAChBT,EAAW,IACb,CAAE,MAAOG,GACT,CAAA,MAAMxa,CACR,CACF,CAKAxB,WAAAA,CACEC,EACAC,EACOwb,EACAC,EACAE,GAEPpQ,MAAMxL,EAASC,GAAYE,KAJpBsb,kBACAC,YAAA,EAAAvb,KACAyb,cARDU,EAAAA,KAAAA,+BACAzM,yBAAmB,EAAA1P,KA8CnBoc,sBAAyBpZ,IAMX,cAAhBhD,KAAKG,QACPH,KAAKF,WAAWiC,YAAY,CAC1Bsa,iBAAkBrP,EAPEhK,EAAMyI,KAAK,GAOuByB,WAKpDoP,KAAAA,uBAAyB,EAAG7Q,WAChB,YAAdA,EAAK3K,MACPd,KAAK2C,WAAW8I,EAAK8Q,SAAW,YAAc,aAEjDvc,KAEOwc,oBAAuBC,IAC7Bzc,KAAKub,OAAOf,KAAKA,KAAKkC,sBACpB1c,KAAKub,OAAOvW,QAAQ2X,aAEtB3c,KAAKub,OAAOf,KAAKA,KAAKoC,MAAQ5c,KAAKI,OACnCJ,KAAKub,OAAOpN,QAAQ+G,KAAKC,YAAY,CAAErU,KAAM,qBAC7Cd,KAAKub,OAAOpN,QAAQ+G,KAAKC,YAAY,CACnCrU,KAAM,SACNoM,OAAQI,EAAoBmP,WAIxBI,aAAe,KAErB7c,KAAK2C,WAAW,aAChB3C,KAAKub,OAAOpN,QAAQ+G,KAAKC,YAAY,CAAErU,KAAM,cAC7Cd,KAAKub,OAAOf,KAAKA,KAAKsC,6BACpB,KACA9c,KAAKub,OAAOvW,QAAQ2X,YAAc,GAIpCpR,WAAW,KACTvL,KAAKub,OAAOf,KAAKA,KAAKoC,MAAQ5c,KAAKI,OACnCJ,KAAKub,OAAOpN,QAAQ+G,KAAKC,YAAY,CAAErU,KAAM,sBAC5C,MAGGic,KAAAA,gBAAmBC,IACzB,GAA6B,IAAzBA,EAAclV,OAChB,OACF,EAIA,IAAI1H,EAAS,EACb,IAAK,IAAIwN,EAAI,EAAGA,EAAIoP,EAAclV,OAAQ8F,IACxCxN,GAAU4c,EAAcpP,GAAK,IAI/B,OAFAxN,GAAU4c,EAAclV,OAEjB1H,EAAS,EAAI,EAAIA,EAAS,EAAI,EAAIA,GAC1CJ,KA0IMyC,UAAY,EAAGrC,aAEpB,MAAM6c,EAAgBpU,OAAOqU,SAAS9c,GAClC+c,KAAKC,IAAI,EAAGD,KAAKE,IAAI,EAAGjd,IACxB,EACJJ,KAAKI,OAAS6c,EAEVjd,KAAKF,sBAAsBoP,EAE7BlP,KAAKF,WAAW6V,eAAesH,GAG/Bjd,KAAKub,OAAOf,KAAKA,KAAKoC,MAAQK,GA5PzBjd,KAAKsb,MAALA,EACAtb,KAAMub,OAANA,EACAvb,KAAQyb,SAARA,EAGPzb,KAAKsb,MAAMnN,QAAQ+G,KAAKE,UAAYpV,KAAKoc,sBACzCpc,KAAKub,OAAOpN,QAAQ+G,KAAKE,UAAYpV,KAAKsc,sBAC5C,CAEmB,sBAAM1b,SACZyK,MAACzK,mBACZ,IAAI,IAAA0c,QACiB,OAAnBA,EAAMtd,KAAKyb,eAAQ,EAAb6B,EAAepB,WACrBlc,KAAKyb,SAAW,IAClB,CAAE,MAAOG,GAAI,OAEP5b,KAAKsb,MAAMxY,cACP9C,KAACub,OAAOzY,OACpB,CAEmB/B,kBAAAA,CAAmBiC,GACpCqI,MAAMtK,mBAAmBiC,GACzBhD,KAAK6c,cACP,CAEmBhb,WAAAA,CAAYmB,GACkC,IAAAua,EAAAC,EAA3Dxd,KAAKC,wBAA0B+C,EAAMyS,YAAYzT,WACnDub,OAAAA,GAAAC,EAAIxd,KAACH,SAAQN,UAAbge,EAAAtZ,KAAAuZ,EAAuBxa,EAAMyS,YAAYC,eAInC1V,KAAKF,sBAAsBoP,GAC/BlP,KAAKwc,oBAAoBxZ,EAAMyS,YAAYC,eAG7C1V,KAAKK,eAAiB2C,EAAMyS,YAAYzT,SACxChC,KAAK+C,wBACL/C,KAAK2C,WAAW,YAEpB,CAiEOwD,WAAAA,CAAYC,GAEbpG,KAAKF,sBAAsBoP,EAC7BlP,KAAKF,WAAWqG,YAAYC,GAG5BpG,KAAKsb,MAAMnB,SAAS/T,EAExB,CAEOC,yBAAAA,GAKL,aAJArG,KAAKmc,qBAALnc,KAAKmc,mBAAuB,IAAIvd,WAC9BoB,KAAKsb,MAAM9B,SAASxC,oBAEtBhX,KAAKsb,MAAM9B,SAASvC,qBAAqBjX,KAAKmc,oBACnCnc,KAACmc,kBACd,CAEO7V,0BAAAA,GAEL,OAAItG,KAAKF,sBAAsBoP,EACVlP,KAAKF,WAAWwG,8BAK5B,IAAI1H,WAAW,OAGA6e,WAAnB/N,sBAAL1P,KAAK0P,oBAAwB,IAAI9Q,WAC/BoB,KAAKub,OAAO/B,SAASxC,oBAEvBhX,KAAKub,OAAO/B,SAASvC,qBAAqBjX,KAAK0P,qBACxC1P,KAAK0P,oBACd,CAEOnJ,cAAAA,GACL,OAAWvG,KAAC+c,gBAAgB/c,KAAKqG,4BACnC,CAEOG,eAAAA,GACL,OAAWxG,KAAC+c,gBAAgB/c,KAAKsG,6BACnC,CAEO,uBAAMoX,EAAkB9U,WAC7BA,EAAUL,OACVA,EAAMkQ,8BACNA,EAA6BC,cAC7BA,IAEA,IAEE,GAAI1Y,KAAKF,sBAAsBmL,EAC7B,IAEE,kBADWqQ,MAAMlB,eAAe1B,QACpB4C,KACd,CAAE,MAAOla,GACP4E,QAAQY,KACN,yDACAxF,EAGJ,CAIEpB,KAAKF,sBAAsBoP,cAClBpP,WAAWoW,oBAAoBwC,GAAiB,UAIvD1Y,KAAKsb,MAAMxY,QAEjB,MAAM6a,QAAiBnF,EAAM9M,OAAO,CAClC9C,WAAYA,MAAAA,EAAAA,EAAc5I,KAAKF,WAAWqL,YAAYvC,WACtDL,OAAc,MAANA,EAAAA,EAAUvI,KAAKF,WAAWqL,YAAY5C,OAC9CkQ,gCACAC,gBACAC,aAAc3Y,KAAKH,QAAQ8Y,aAC3BC,kBAAmB5Y,KAAKH,QAAQ+Y,oBAMlC,OAHA5Y,KAAKsb,MAAQqC,EACb3d,KAAKsb,MAAMnN,QAAQ+G,KAAKE,UAAYpV,KAAKoc,sBAElCpc,KAAKsb,KACd,CAAE,MAAOla,GAEP,MADA4E,QAAQ5E,MAAM,8BAA+BA,GACvCA,CACR,CACF,CAEO,wBAAMwc,EAAmBhV,WAC9BA,EAAUL,OACVA,EAAMiH,eACNA,IAEA,IAEE,GAAIxP,KAAKF,sBAAsBmL,EAC7B,IAEE,kBADWsQ,OAAOJ,gBAAgB3L,QACtB+L,MACd,CAAE,MAAOna,GACP4E,QAAQY,KACN,0DACAxF,EAGJ,CAIEpB,KAAKF,sBAAsBoP,SACvBlP,KAAKF,WAAW8V,qBAAqBpG,GAAkB,UAIzDxP,KAAKub,OAAOzY,QAElB,MAAM+a,QAAkBtD,EAAO7O,OAAO,CACpC9C,WAAYA,MAAAA,EAAAA,EAAc5I,KAAKF,WAAWsL,aAAaxC,WACvDL,OAAc,MAANA,EAAAA,EAAUvI,KAAKF,WAAWsL,aAAa7C,OAC/CiH,iBACAmJ,aAAc3Y,KAAKH,QAAQ8Y,eAK7B,OAFA3Y,KAAKub,OAASsC,OAEFtC,MACd,CAAE,MAAOna,GAEP,MADA4E,QAAQ5E,MAAM,+BAAgCA,GACxCA,CACR,CACF,ECjUI,SAAU0c,EACdpb,EACAqb,EACAlS,EAtBuB,6BAwBvB,MAAMiH,EAIF,GASJ,MAP8B,kBAAnBiL,EACTjL,EAAKkL,SAAWD,EAAiB,OAAS,WAE1CjL,EAAKmL,OAASF,EAAeE,OAC7BnL,EAAKoL,QAAUH,EAAeG,SAGzBpO,MAAM,GAAGjE,6BAAkCnJ,aAA2B,CAC3Eyb,OAAQ,OACRrL,KAAMxO,KAAKC,UAAUuO,GACrBsL,QAAS,CACP,eAAgB,qBAGtB,CCVA,MAAMC,EAAYze,WAAAA,QACR0e,UAA4D,IAAIvQ,GAAK,CAE7E+C,EAAAA,CAAG9N,EAAeub,GACXve,KAAKse,UAAUE,IAAIxb,IACtBhD,KAAKse,UAAU9P,IAAIxL,EAAO,IAAIyb,KAEhC,MAAMC,EAAiB1e,KAAKse,UAAUhQ,IAAItL,GACtC0b,GACFA,EAAeC,IAAIJ,EAEvB,CAEA5N,GAAAA,CAAI3N,EAAeub,GACjB,MAAMG,EAAiB1e,KAAKse,UAAUhQ,IAAItL,GACtC0b,GACFA,EAAeE,OAAOL,EAE1B,CAEAM,IAAAA,CAAK7b,KAAkB8b,GACrB,MAAMJ,EAAiB1e,KAAKse,UAAUhQ,IAAItL,GACtC0b,GACFA,EAAe1W,QAAQuW,IACrBA,KAAYO,IAGlB,EAMU,IAAAC,GAAZ,SAAYA,GAEVA,EAAA,gBAAA,kBAEAA,EAAA,mBAAA,qBAEAA,EAAA,qBAAA,uBAEAA,EAAA,qCAAA,uCAEAA,EAAA,WAAA,aAEAA,EAAA,MAAA,QAEAA,EAAA,KAAA,OAEAA,EAAA,MAAA,QAEAA,EAAA,eAAA,gBACD,CAnBD,CAAYA,IAAAA,EAmBX,KAkCY,MAAAC,EAMXpf,WAAAA,CAAYgJ,GAAkB5I,KALtBif,UAA8B,KAAIjf,KAClCkf,aAA6B,IAAIb,EACjCc,KAAAA,kBAA4B,KAAKnf,KAClCof,mBAAa,EAGlBpf,KAAKmf,kBAAoBvW,CAC3B,CAMOyW,YAAAA,CAAaJ,GAClBjf,KAAKif,UAAYA,EAGbjf,KAAKif,UAAUK,aAAelT,UAAUmT,KAC1Cvf,KAAKkf,aAAaL,KAAKE,EAAeQ,MAGtCvf,KAAKif,UAAU3T,iBAAiB,OAAQ,KACtCtL,KAAKkf,aAAaL,KAAKE,EAAeQ,QAI1Cvf,KAAKif,UAAU3T,iBAAiB,UAAYtI,IAC1C,IACE,MAAMyI,EAAOnH,KAAKkH,MAAMxI,EAAMyI,MAE9B,OAAQA,EAAK+T,cACX,IAAK,kBACHxf,KAAKkf,aAAaL,KAAKE,EAAeU,gBAAiBhU,GACvD,MACF,IAAK,qBACHzL,KAAKkf,aAAaL,KAAKE,EAAeW,mBAAoBjU,GAC1D,MACF,IAAK,uBACHzL,KAAKkf,aAAaL,KAAKE,EAAeY,qBAAsBlU,GAC5D,MACF,IAAK,uCACHzL,KAAKkf,aAAaL,KAChBE,EAAea,qCACfnU,GAEF,MACF,IAAK,aACHzL,KAAKkf,aAAaL,KAAKE,EAAec,WAAYpU,GAClD,MACF,IAAK,iBACHzL,KAAKkf,aAAaL,KAAKE,EAAee,eAAgBrU,GACtD,MACF,IAAK,QACHzL,KAAKkf,aAAaL,KAAKE,EAAegB,MAAOtU,GAC7C,MACF,QACEzF,QAAQY,KAAK,wBAAyB6E,GAE5C,CAAE,MAAOrK,GACP4E,QAAQ5E,MAAM,qCAAsCA,EAAO4B,EAAMyI,MACjEzL,KAAKkf,aAAaL,KAChBE,EAAegB,MACf,IAAI1e,MAAM,4BAA4BD,KAE1C,IAGFpB,KAAKif,UAAU3T,iBAAiB,QAAUlK,IACxC4E,QAAQ5E,MAAM,mBAAoBA,GAClCpB,KAAKkf,aAAaL,KAAKE,EAAegB,MAAO3e,KAG/CpB,KAAKif,UAAU3T,iBAAiB,QAAUtI,IAMxC,GALAgD,QAAQga,IACN,0BAA0Bhd,EAAM4C,iBAAiB5C,EAAMH,qBAAqBG,EAAMid,aAI/Ejd,EAAMid,UAA4B,MAAfjd,EAAM4C,MAAgC,OAAf5C,EAAM4C,KAAgB,CACnE,MAAMsa,EAAe,kCAAkCld,EAAM4C,UAAU5C,EAAMH,QAAU,uBACvFmD,QAAQ5E,MAAM8e,GACdlgB,KAAKkf,aAAaL,KAAKE,EAAegB,MAAO,IAAI1e,MAAM6e,GACzD,CAEAlgB,KAAKkf,aAAaL,KAAKE,EAAeoB,MAAOnd,IAEjD,CAuBO8N,EAAAA,CACL9N,EACAub,GAEAve,KAAKkf,aAAapO,GAAG9N,EAAOub,EAC9B,CAiBO5N,GAAAA,CACL3N,EACAub,GAEAve,KAAKkf,aAAavO,IAAI3N,EAAOub,EAC/B,CA0BO7R,IAAAA,CAAKjB,GAIX,IAAA2U,EAAAC,EACC,IAAKrgB,KAAKif,WAAajf,KAAKif,UAAUK,aAAelT,UAAUmT,KAC7D,MAAU,IAAAle,MAAM,8BAGlB,MAAMC,EAA2B,CAC/Bke,aAAc,oBACd9J,cAAejK,EAAK6U,YACpBC,OAAmB,OAAbH,EAAE3U,EAAK8U,SAAMH,EACnBI,YAA4B,OAAjBH,EAAE5U,EAAK7C,YAAUyX,EAAIrgB,KAAKmf,mBAGvCnf,KAAKif,UAAUvS,KAAKpI,KAAKC,UAAUjD,GACrC,CAuBOif,MAAAA,GACL,IAAKvgB,KAAKif,WAAajf,KAAKif,UAAUK,aAAelT,UAAUmT,KAC7D,UAAUle,MAAM,8BAUlBrB,KAAKif,UAAUvS,KAAKpI,KAAKC,UAPQ,CAC/Bib,aAAc,oBACd9J,cAAe,GACf6K,QAAQ,EACRC,YAAaxgB,KAAKmf,oBAItB,CAkBOrc,KAAAA,GAED9C,KAAKof,eACPpf,KAAKof,gBAIHpf,KAAKif,WACPjf,KAAKif,UAAUnc,OAEnB,ECzWK,MAAM2d,EAA2BzS,EACtC,uBAEA,ogDCHU,IAAA0S,EAUAC,GAVZ,SAAYD,GACVA,EAAA,SAAA,WACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,WACD,CARD,CAAYA,IAAAA,EAQX,CAAA,IAED,SAAYC,GACVA,EAAA,OAAA,SACAA,EAAA,IAAA,KACD,CAHD,CAAYA,IAAAA,EAGX,CAAA,UAiFYC,EAGH,sBAAOC,CACbC,EAAkBF,EAAeG,kBAEjC,MAAO,GAAGD,8BACZ,CAEQ,wBAAOE,CACbnhB,GAEA,MAAMihB,EAAUF,EAAeC,gBAAgBhhB,EAAQihB,SACjDG,EAAS,IAAIC,gBAWnB,GARAD,EAAOE,OAAO,WAAYthB,EAAQuhB,SAElCH,EAAOE,OAAO,QAASthB,EAAQqQ,YAGAmR,IAA3BxhB,EAAQyhB,gBACVL,EAAOE,OAAO,kBAAmBthB,EAAQyhB,qBAEHD,IAApCxhB,EAAQ0hB,wBAAuC,CACjD,GACE1hB,EAAQ0hB,yBAA2B,IACnC1hB,EAAQ0hB,wBAA0B,EAElC,MAAM,IAAIlgB,MAAM,uDAElB4f,EAAOE,OACL,6BACAthB,EAAQ0hB,wBAAwBpQ,WAEpC,CACA,QAA6BkQ,IAAzBxhB,EAAQ2hB,aAA4B,CACtC,GAAI3hB,EAAQ2hB,aAAe,IAAO3hB,EAAQ2hB,aAAe,GACvD,MAAM,IAAIngB,MAAM,4CAElB4f,EAAOE,OAAO,gBAAiBthB,EAAQ2hB,aAAarQ,WACtD,CACA,QAAoCkQ,IAAhCxhB,EAAQ4hB,oBAAmC,CAC7C,GACE5hB,EAAQ4hB,qBAAuB,IAC/B5hB,EAAQ4hB,oBAAsB,IAE9B,MAAU,IAAApgB,MAAM,mDAElB4f,EAAOE,OACL,yBACAthB,EAAQ4hB,oBAAoBtQ,WAEhC,CACA,QAAqCkQ,IAAjCxhB,EAAQ6hB,qBAAoC,CAC9C,GACE7hB,EAAQ6hB,sBAAwB,IAChC7hB,EAAQ6hB,qBAAuB,IAE/B,UAAUrgB,MAAM,oDAElB4f,EAAOE,OACL,0BACAthB,EAAQ6hB,qBAAqBvQ,WAEjC,MAC6BkQ,IAAzBxhB,EAAQ8hB,cACVV,EAAOE,OAAO,gBAAiBthB,EAAQ8hB,mBAEPN,IAA9BxhB,EAAQ+hB,mBACVX,EAAOE,OACL,qBACAthB,EAAQ+hB,kBAAoB,OAAS,SAIzC,MAAMC,EAAcZ,EAAO9P,WAC3B,OAAO0Q,EAAc,GAAGf,KAAWe,IAAgBf,CACrD,CA6BO,cAAOrQ,CACZ5Q,GAEA,IAAKA,EAAQuhB,QACX,MAAM,IAAI/f,MAAM,uBAIlB,MAIMvB,EAAa,IAAIkf,EAHrB,eAAgBnf,GAAWA,EAAQiiB,WAC/B,KACCjiB,EAAyB+I,YAI1BmZ,EAAMnB,EAAeI,kBAAkBnhB,GAEvCof,EAAY,IAAI7S,UAAU2V,GAchC,MAXI,eAAgBliB,GAAWA,EAAQiiB,YACrC7C,EAAU3T,iBAAiB,OAAQ,KACjCsV,EAAeoB,qBACbniB,EACAC,KAKNA,EAAWuf,aAAaJ,GAEjBnf,CACT,CAEQ,iCAAakiB,CACnBniB,EACAC,GAEA,IAAI,IAAAmiB,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAEF,MAAM1H,QAAezD,UAAUyB,aAAaa,aAAa,CACvDC,MAAO,CACLhE,SAA4B,OAApBoM,EAAEpiB,EAAQiiB,iBAAU,EAAlBG,EAAoBpM,SAC9BU,iBAAsD,OAAtC2L,EAAoB,OAApBC,EAAEtiB,EAAQiiB,iBAAU,EAAlBK,EAAoB5L,mBAAgB2L,EACtD1L,iBAAsD,OAAtC4L,EAAoB,OAApBC,EAAExiB,EAAQiiB,iBAAU,EAAlBO,EAAoB7L,mBAAgB4L,EACtD3L,gBAAoD,OAArC6L,EAAEC,OAAFA,EAAE1iB,EAAQiiB,iBAARS,EAAAA,EAAoB9L,kBAAe6L,EACpD5L,aAA8C,OAAlC8L,EAAoB,OAApBC,EAAE5iB,EAAQiiB,iBAAU,EAAlBW,EAAoB/L,cAAY8L,EAAI,EAClD5Z,WAAY,CAAE+N,MAAO,SAKnBpC,EAAe,IAAIC,aAAa,CAAE5L,WAAY,aAG9C6X,EAAyBlM,EAAaS,cAG5C,MAAM9R,EAASqR,EAAaQ,wBAAwBgG,GAC9C2H,EAAc,IAAIzN,iBACtBV,EACA,wBAIFmO,EAAYxN,KAAKE,UAAYpS,IAC3B,MAAMqS,UAAEA,GAAcrS,EAAMyI,KAEtBkC,EAAQ,IAAI/O,WAAWyW,GAC7B,IAAIsN,EAAS,GACb,IAAK,IAAI/U,EAAI,EAAGA,EAAID,EAAM7F,OAAQ8F,IAChC+U,GAAUphB,OAAO8L,aAAaM,EAAMC,IAEtC,MAAM2H,EAAcnI,KAAKuV,GAEzB7iB,EAAW4M,KAAK,CAAE4T,YAAa/K,KAIjCrS,EAAOuN,QAAQiS,GAGY,cAAvBnO,EAAalD,aACTkD,EAAauF,SAIrBha,EAAWsf,cAAgB,KACzBrE,EAAOd,YAAYjS,QAAQ6J,IACzBA,EAAMyB,SAERpQ,EAAOgF,aACPwa,EAAYxa,aACZqM,EAAazR,QAEjB,CAAE,MAAO1B,GAEP,MADA4E,QAAQ5E,MAAM,wCAAyCA,GACjDA,CACR,CACF,EA9MWwf,EACaG,iBAAmB,0BC5CvC,MAAO6B,UAAqB/jB,EACzB,mBAAOsZ,CAAatY,GACzB,OAAOA,EAAQ0K,SACX2N,EAAiBC,aAAatY,GAC9Bub,EAAkBjD,aAAatY,EACrC"}